# -*- coding: utf-8 -*-
"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  SYSTEM DIAGNOSTYKI ≈ÅO≈ªYSK ‚Äî LINIA TARTAKU                                ‚ïë
‚ïë  Condition Monitoring Engine v1.0                                          ‚ïë
‚ïë                                                                            ‚ïë
‚ïë  Metodyka:                                                                 ‚ïë
‚ïë    1. SKF ‚Äî Crest Factor (wsp√≥≈Çczynnik szczytu wibracji)                   ‚ïë
‚ïë    2. Siemens ‚Äî Baseline Deviation (adaptacyjna linia bazowa 7-dniowa)     ‚ïë
‚ïë    3. AWS Amazon Monitron ‚Äî Anomaly Gradient (gradient temperatury)         ‚ïë
‚ïë                                                                            ‚ïë
‚ïë  Cel: Odr√≥≈ºniƒá "stary wiek maszyny" od "nadchodzƒÖcej katastrofy"          ‚ïë
‚ïë  Dane wej≈õciowe: CSV z czujnik√≥w IoT (timestamp, unit, value)             ‚ïë
‚ïë  Autor: IIoT Condition Monitoring Engineer                                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Uzasadnienie biznesowe:
    Standardowe alarmy statystyczne (pr√≥g 70¬∞C, wibracje > 4g) nie dzia≈ÇajƒÖ
    w starych maszynach tartaku, poniewa≈º ich "normalny" poziom szumu jest
    wy≈ºszy ni≈º normy ISO 10816 dla nowych maszyn. Ten system stosuje
    podej≈õcie relatywne ‚Äî por√≥wnuje maszynƒô do niej samej, nie do ksiƒÖ≈ºkowych
    norm.

Referencje standard√≥w:
    - SKF Application Note: "Vibration Diagnostic Guide" (wsp√≥≈Çczynnik szczytu)
    - ISO 10816-3:2009 ‚Äî Wibracje maszyn (kontekst, nie progi)
    - Siemens SITRANS MS200 / MindSphere ‚Äî Predictive Analytics (adaptive baseline)
    - AWS Amazon Monitron ‚Äî Machine Learning anomaly detection (gradient-based)
    - ISO 13373-1:2002 ‚Äî Condition monitoring and diagnostics of machines
"""

import pandas as pd
import numpy as np
from datetime import timedelta, time
import warnings
import os
import sys
import io

# Wymu≈õ UTF-8 dla konsoli Windows
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except (AttributeError, io.UnsupportedOperation):
        pass

warnings.filterwarnings('ignore')

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  KONFIGURACJA ‚Äî PROGI ALARMOWE
#  Dostosuj do specyfiki swojej linii produkcyjnej.
#  Ka≈ºdy pr√≥g jest udokumentowany odniesieniem do standardu bran≈ºowego.
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# --- SKF: Crest Factor (Wsp√≥≈Çczynnik Szczytu) ---
# Ref: SKF Application Note ‚Äî "Bearing damage and failure analysis"
# CF = Peak / RMS. Nowe ≈Ço≈ºysko: CF ‚âà 3. Uszkodzenie bie≈ºni: CF > 5-6.
# Gdy CF ro≈õnie powy≈ºej 5, oznacza to impulsy mechaniczne (pƒôkniƒôcia kulek,
# odpryski bie≈ºni) ‚Äî zanim jeszcze wzro≈õnie temperatura.
SKF_CF_NORMAL = 3.0       # CF < 3.0 ‚Üí ≈Ço≈ºysko zdrowe
SKF_CF_WARNING = 5.0      # 3.0 ‚â§ CF < 5.0 ‚Üí wczesne mikro-pittingi
SKF_CF_CRITICAL = 6.0     # CF ‚â• 6.0 ‚Üí powa≈ºne uszkodzenie fizyczne
SKF_VIBRATION_IDLE = 0.1  # g ‚Äî Idle bypass (ignoruje wibracje t≈Ça poni≈ºej 0.1g)

# --- Siemens: Baseline Deviation (Adaptacyjna Banda Statystyczna) ---
# Ref: Siemens MindSphere / AWS Monitron ‚Äî adaptive statistical bands
# Zamiast sztywnego "25% odchylenia" (kt√≥ry nie uwzglƒôdnia naturalnej
# zmienno≈õci maszyny), stosujemy bandƒô Œº ¬± N√óœÉ.
# Je≈õli maszyna normalnie waha siƒô ¬±15%, banda bƒôdzie szersza.
# Je≈õli maszyna jest stabilna (¬±3%), banda bƒôdzie cia≈õniejsza.
SIEMENS_BASELINE_WINDOW = '30D'  # Okno bazowe: 30 dni (~20 cykli produkcyjnych)
                                  # 7 dni to za ma≈Ço dla maszyn start-stop (tylko ~5 cykli)
SIEMENS_SIGMA_WARNING = 2.0      # Œº ¬± 2œÉ ‚Üí PLANLEGG SERVICE (üü°) (95.4% pewno≈õci anomalii)
SIEMENS_SIGMA_CRITICAL = 3.0     # Œº ¬± 3œÉ ‚Üí KRITISK ALARM (üî¥) (99.7% pewno≈õci anomalii)
SIEMENS_STEADYSTATE_WINDOW = 6   # Interwa≈Çy (30 min) do oceny stabilno≈õci maszyny
SIEMENS_STEADYSTATE_CV_MAX = 0.15  # Max wsp√≥≈Çczynnik zmienno≈õci (15%) = steady state

# --- AWS Monitron: Anomaly Gradient (Gradient Temperatury) ---
# Ref: AWS Monitron ‚Äî "Abnormal condition detection using rate of change"
# KALIBRACJA na podstawie rzeczywistego po≈ºaru 13.02.2026:
#   - Prawdziwy po≈ºar: gradient +23¬∞C/h ‚Üí +57¬∞C/h (o 07:15-07:20)
#   - Normalna praca: 99.9 percentyl = +14.4¬∞C/h
#   - PR√ìG MIƒòDZY NIMI: 15¬∞C/h
# UWAGA: Tylko DODATNIE gradienty (grzanie) sƒÖ niebezpieczne.
# Ujemny gradient = ch≈Çodzenie = BEZPIECZNE.
AWS_GRADIENT_WINDOW = '1h'       # Okno oblicze≈Ñ gradientu
AWS_GRADIENT_WARNING = 10.0      # ¬∞C/h ‚Üí Warning
AWS_GRADIENT_CRITICAL = 15.0     # ¬∞C/h ‚Üí Critical / Fire (üî¥üî•)
AWS_GRADIENT_FIRE_EXTREME = 30.0 # ¬∞C/h ‚Üí Extreme Fire (natychmiastowy stop linii)
AWS_MIN_FIRE_TEMP = 45.0         # ¬∞C ‚Üí Minimalna temp wymagana dla po≈ºaru
# --- NOWY: Pod≈Çoga wibracji dla alarm√≥w krytycznych ---
# Chroni przed nadawaniem statusu BRANN na bardzo cichych maszynach (np. 0.3g)
# kt√≥re statystycznie majƒÖ anomaliƒô, ale fizycznie nic im nie grozi.
SIEMENS_MIN_CRITICAL_RMS = 0.3   # g 

# Dzie≈Ñ produkcyjny: 06:00 ‚Äî 23:20
# Przerwy: 09:30‚Äì10:00 (≈õniadanie), 19:00‚Äì19:30 (kolacja)
# Poza tymi godzinami maszyna jest wy≈ÇƒÖczona ‚Äî ignoruj szum czujnik√≥w.
# Gradienty na granicach start/stop/przerwa sƒÖ naturalne i NIE powinny
# wywo≈Çywaƒá alarm√≥w (nagrzewanie zimnego ≈Ço≈ºyska ‚â† awaria).
PRODUCTION_START = time(6, 0)     # Start zmiany: 06:00
PRODUCTION_END = time(23, 20)     # Koniec zmiany: 23:20
BREAKS = [
    (time(9, 30), time(10, 0)),   # Przerwa ≈õniadaniowa
    (time(19, 0), time(19, 30)),  # Przerwa kolacyjna
]
# Ile minut po starcie/przerwie ignorowaƒá gradient (czas nagrzewania)
WARMUP_MINUTES = 60

# --- Alarm Persistence (Trwa≈Ço≈õƒá Alarmu) ---
# Ref: SKF Enlight / IMx ‚Äî alarm debounce
# Pojedynczy spike wibracji (np. w√≥zek wid≈Çowy, uderzenie k≈Çody) nie powinien
# wywo≈Çywaƒá alarmu. Prawdziwa degradacja ≈Ço≈ºyska trwa ‚Äî jest widoczna
# w KOLEJNYCH pr√≥bkach. Wymagamy N kolejnych interwa≈Ç√≥w powy≈ºej progu.
ALARM_PERSISTENCE_INTERVALS = 2  # 2 √ó 5min = 10 minut ciƒÖg≈Çego alarmu dla standardowej pompy/silnika
ALARM_PERSISTENCE_FIRE = 1       # 1 √ó 5min = NATYCHMIAST dla PO≈ªAR/STOP (W u≈Çamku sekund temperatura nie robi false spikes, tylko p≈Çonie!)
# Po≈ºar (Gradient > 15C/h) nie podlega zw≈Çoce! Bezw≈Çadno≈õƒá cieplna litego ≈ºeliwa 
# uniemo≈ºliwia b≈Çƒôdy pomiarowe np. o 20 stopni / h z powietrza. 
# Czekanie 15 minut przy po≈ºarze to pewne spalenie linii.

# --- HEAVY IMPACT PROFILE (RƒòBAKI / QSS) ---
# Wprowadzamy osobne, u≈Çagodzone kryteria dla maszyn brutalnie tnƒÖcych k≈Çody (np. 1880 QSS-420).
# Rƒôbaki zƒôbowe produkujƒÖ nieko≈ÑczƒÖcy siƒô ciƒÖg szpilek wibracyjnych - standardowo ISO/SKF zarzuca≈Çyby alarmami przez ca≈Çy dzie≈Ñ.
HEAVY_KEYWORDS = ['QSS', 'HUGG', 'CHIPPER', 'REBAK', 'RƒòBAK']
HEAVY_SKF_CF_WARNING = 6.0       # Standardowy to 5.0 (dopuszczamy rƒôbaki do ciƒôcia twardszych materia≈Ç√≥w)
HEAVY_SKF_CF_CRITICAL = 8.0      # Standardowy to 6.0
# Znaczne wyd≈Çu≈ºenie debouncingu dla rƒôbak√≥w ‚Äî ≈ºeby zignorowaƒá np. twardƒÖ krzywƒÖ k≈Çodƒô.
HEAVY_ALARM_PERSISTENCE_INTERVALS = 5  # 5 √ó 5min = 25 minut ciƒÖg≈Çego ha≈Çasu bezlitosnego bicia wa≈Çu, by odpaliƒá ALARM.

# --- Random Cut Forest (4. silnik: AWS Monitron ML) ---
# Ref: AWS Monitron ‚Äî "Robust Random Cut Forest Based Anomaly Detection"
# Ref: Guha et al., 2016 ‚Äî "Robust Random Cut Forest" (ICML)
# RCF analizuje WIELE wymiar√≥w jednocze≈õnie (temperatura, wibracje, CF, gradient)
# i szuka punkt√≥w, kt√≥re sƒÖ "≈Çatwe do oddzielenia" od reszty danych.
# To samo co AWS Monitron robi wewnƒôtrznie na czujnikach.
RCF_NUM_TREES = 100              # Ilo≈õƒá drzew w lesie (wiƒôcej = stabilniejsze wyniki)
RCF_TREE_SIZE = 256              # Max punkt√≥w na drzewo (okno uczenia)
RCF_FEATURES = [                 # Cechy wej≈õciowe ‚Äî wielowymiarowa analiza
    'vib_rms',                   #   Energia wibracji
    'temp_mean',                 #   Temperatura ≈Ço≈ºyska
    'crest_factor',              #   Impulsowo≈õƒá sygna≈Çu (SKF)
    'temp_gradient_final',       #   Szybko≈õƒá zmian temperatury (AWS)
    'avg_line_vibration'         #   Korelacja Sagi ‚Äî ≈õrednia wibracja na Linii
]
# --- ISO 10816-1: Vibration Severity (Absolute Norms) ---
# Klasa I: Ma≈Çe maszyny (do 15 kW) ‚Äî standard dla przeno≈õnik√≥w
ISO_VIB_ZONE_A_B = 0.71  # mm/s (Granica miƒôdzy Dobrym a ZadowalajƒÖcym)
ISO_VIB_ZONE_B_C = 1.80  # mm/s (Granica miƒôdzy ZadowalajƒÖcym a NiepokojƒÖcym)
ISO_VIB_ZONE_C_D = 4.50  # mm/s (Granica miƒôdzy NiepokojƒÖcym a Niedopuszczalnym)

# Progi anomalii RCF (Random Cut Forest) kalibrowane automatycznie z danych:
RCF_PERCENTILE_WARNING = 99.0    # Score > 99.0-ty percentyl ‚Üí PLANLEGG SERVICE
RCF_PERCENTILE_CRITICAL = 99.9   # Score > 99.9-ty percentyl ‚Üí KRITISK ALARM

# --- Agregacja ---
AGGREGATION_INTERVAL = '5min'    # Interwa≈Ç pr√≥bkowania: 5 minut


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 1: ≈ÅADOWANIE I PRZYGOTOWANIE DANYCH
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def load_sensor_data(filepath: str) -> pd.DataFrame:
    """
    Wczytaj dane z CSV eksportowanego z systemu IoT.
    Format: sn;time;unit;value;timestamp
    Separator: ; (standard europejski)
    """
    print(f"  [LOAD] {os.path.basename(filepath)}")
    df = pd.read_csv(
        filepath,
        sep=';',
        dtype={'sn': str, 'unit': str, 'value': float}
    )
    df['timestamp'] = pd.to_datetime(df['timestamp'], format='ISO8601')
    
    # Skrypt pobiera≈Ç czas UTC z CSV i gubi≈Ç polskƒÖ strefƒô (zima +1, lato +2)
    # Ratuje to przeliczenie na Europe/Warsaw i zrzucenie obrysu z UTC by pƒôtle czasu 06:00 itp dzia≈Ça≈Çy precyzyjnie.
    if df['timestamp'].dt.tz is not None:
        df['timestamp'] = df['timestamp'].dt.tz_convert('Europe/Warsaw').dt.tz_localize(None)

    df = df.sort_values('timestamp').reset_index(drop=True)
    print(f"     ‚Üí {len(df):,} rekord√≥w, zakres (PL): {df['timestamp'].min()} ‚Äî {df['timestamp'].max()}")
    return df


def prepare_bearing_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Rozdziel dane ≈Ço≈ºyskowe na kana≈Çy wibracji (g) i temperatury (¬∞C).
    Agreguj do interwa≈Ç√≥w 5-minutowych.

    Agregacja wibracji:
      - max: warto≈õƒá szczytowa (peak) ‚Äî potrzebna do Crest Factor (SKF)
      - mean: ≈õrednia ‚Äî potrzebna do baseline (Siemens)
      - rms: ‚àö(mean(x¬≤)) ‚Äî standard ISO 10816 dla oceny wibracji
      - std: odchylenie standardowe ‚Äî informacja dodatkowa

    Agregacja temperatury:
      - mean: ≈õrednia w oknie ‚Äî wystarczajƒÖca dla gradientu (AWS Monitron)
    """
    # Rozdziel kana≈Çy
    if 'vib_rms' in df.columns and 'temp_mean' in df.columns:
        # Format "wide" (nowy daemon) - przygotuj do agregacji
        vib = df[['timestamp', 'vib_rms']].copy().rename(columns={'vib_rms': 'value'})
        vib['unit'] = 'g'
        temp = df[['timestamp', 'temp_mean']].copy().rename(columns={'temp_mean': 'value'})
        temp['unit'] = '¬∞C'
    else:
        # Format "long" (klasyczny CSV)
        vib = df[df['unit'] == 'g'].copy()
        temp = df[df['unit'] == '¬∞C'].copy()

    vib = vib.set_index('timestamp')
    temp = temp.set_index('timestamp')

    # Agregacja wibracji co 5 minut
    # RMS obliczamy rƒôcznie: ‚àö(mean(x¬≤))
    vib_agg = vib['value'].resample(AGGREGATION_INTERVAL).agg(
        vib_max='max',
        vib_mean='mean',
        vib_std='std',
        vib_count='count'
    )

    # RMS = ‚àö(mean(x¬≤)) ‚Äî standard ISO 10816 dla oceny energii wibracji
    vib_rms = vib['value'].resample(AGGREGATION_INTERVAL).apply(
        lambda x: np.sqrt(np.mean(x**2)) if len(x) > 0 else 0
    ).rename('vib_rms')

    # Agregacja temperatury co 5 minut
    temp_agg = temp['value'].resample(AGGREGATION_INTERVAL).agg(
        temp_mean='mean',
        temp_max='max',
        temp_min='min'
    )

    # Po≈ÇƒÖcz w jednƒÖ ramkƒô
    result = pd.concat([vib_agg, vib_rms, temp_agg], axis=1)

    # Uzupe≈Çnij brakujƒÖce interwa≈Çy (forward fill z limitem 3 pr√≥bek = 15min)
    result = result.ffill(limit=3)
    
    # [POPRAWKA] Nie wyrzucaj rekord√≥w, kt√≥re majƒÖ tylko temperaturƒô (np. czujnik hali)
    # Wyrzucamy tylko je≈õli NIE MA ANI temperatury ANI wibracji
    result = result.dropna(how='all', subset=['vib_rms', 'temp_mean'])
    
    # Zapewnij 0.0 zamiast NaN dla wibracji je≈õli ich brak (bezpieczne dla dashboardu)
    if 'vib_rms' in result.columns:
        result['vib_rms'] = result['vib_rms'].fillna(0.0)
    if 'vib_max' in result.columns:
        result['vib_max'] = result['vib_max'].fillna(0.0)

    print(f"     ‚Üí Zagregowano do {len(result)} interwa≈Ç√≥w 5-min")

    # Oznacz harmonogram produkcji
    result = classify_production_time(result)
    prod_count = result['is_production'].sum()
    break_count = result['is_break'].sum()
    idle_count = len(result) - prod_count - break_count
    print(f"     ‚Üí Produkcja: {prod_count} | Przerwy: {break_count} | Poza zmianƒÖ: {idle_count}")

    return result


def classify_production_time(df: pd.DataFrame) -> pd.DataFrame:
    """
    Oznacz ka≈ºdy interwa≈Ç jako: produkcja, przerwa, lub poza zmianƒÖ ZALE≈ªNIE OD DANYCH RZECZYWISTYCH.
    Saga i rƒôbaki to uk≈Çady dynamiczne, czƒôsto stajƒÖ poza harmonogramem.
    
    Nowa logika behawioralna:
      - Silnik pracuje (is_production = True), je≈ºeli vib_rms > bieg ja≈Çowy.
      - Przerwa (is_break = True), je≈ºeli silnik fizycznie stoi.
      - Warmup odpalany na starcie danego silnika.
    """
    df = df.copy()

    # Silnik pracuje, je≈õli wibracje przekraczajƒÖ pr√≥g szumu ja≈Çowego
    df['is_production_raw'] = df['vib_rms'] > SKF_VIBRATION_IDLE

    # --- AWS MACHINE STATE GATING (Czas Wybiegu / Run-down) ---
    # Zamiast ucinaƒá produkcjƒô natychmiast (co powoduje anomalie matematyczne w RCF),
    # dodajemy czas wybiegu (np. 15 minut) od momentu fizycznego zej≈õcia poni≈ºej progu.
    interval_minutes = int(pd.Timedelta(AGGREGATION_INTERVAL).total_seconds() / 60)
    rundown_intervals = 15 // interval_minutes
    
    # Wykrywamy moment zatrzymania: wyrywamy przej≈õcie z 'pracuje' na 'nie pracuje'
    stops = ~df['is_production_raw'] & df['is_production_raw'].shift(1, fill_value=False)
    
    # RozciƒÖgamy flagƒô zatrzymania w prz√≥d o N interwa≈Ç√≥w, definiujƒÖc fazƒô wybiegu (stygniƒôcia)
    is_rundown = stops.replace(False, np.nan).ffill(limit=rundown_intervals).fillna(False).astype(bool)

    # Ostateczna definicja produkcji to: fizyczna praca LUB fizyczne stygniƒôcie na wybiegu
    df['is_production'] = df['is_production_raw'] | is_rundown
    df['is_rundown'] = is_rundown

    # Przerwa to czas, gdy maszyna (silnik) nie pracuje i nie jest w reaktorze wybiegu
    df['is_break'] = ~df['is_production']

    # Wykrywanie "warmupu" (rozgrzewki)
    # Znajdujemy momenty startu (przej≈õcie z false do true dla is_production)
    starts = df['is_production'] & ~df['is_production'].shift(1, fill_value=False)

    interval_minutes = int(pd.Timedelta(AGGREGATION_INTERVAL).total_seconds() / 60)
    warmup_intervals = WARMUP_MINUTES // interval_minutes
    
    # Tworzymy maskƒô rozgrzewki: przed≈Çu≈ºamy flagƒô startu na prz√≥d o 'warmup_intervals' interwa≈Ç√≥w
    df['is_warmup'] = starts.replace(False, np.nan).ffill(limit=warmup_intervals).fillna(False).astype(bool)
    
    # Ciep≈Ço ma znaczenie tylko wtedy, gdy maszyna rzeczywi≈õcie pracuje
    df['is_warmup'] = df['is_warmup'] & df['is_production']

    return df


def prepare_hall_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Przygotuj dane temperatury hali jako referencjƒô otoczenia.
    U≈ºywane do kompensacji: ŒîT_skorygowane = T_≈Ço≈ºysko - T_hala
    """
    if 'temp_mean' in df.columns:
        # Format wide
        temp = df[['timestamp', 'temp_mean']].copy().rename(columns={'temp_mean': 'value'})
    else:
        # Format long
        temp = df[df['unit'] == '¬∞C'].copy()

    temp = temp.set_index('timestamp')

    hall_agg = temp['value'].resample(AGGREGATION_INTERVAL).agg(
        hall_temp='mean'
    )
    hall_agg = hall_agg.ffill(limit=6)  # Czujnik halowy ma rzadsze odczyty

    print(f"     ‚Üí Temperatura hali: {len(hall_agg)} interwa≈Ç√≥w")
    return hall_agg


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 2: LOGIKA SKF ‚Äî CREST FACTOR (Wsp√≥≈Çczynnik Szczytu)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def analyze_skf_crest_factor(df: pd.DataFrame, is_heavy_machinery: bool = False) -> pd.DataFrame:
    """
    SKF Crest Factor Analysis ‚Äî wykrywanie uszkodze≈Ñ mechanicznych ≈Ço≈ºysk.
    """
    df = df.copy()

    # Wyb√≥r prog√≥w w zale≈ºno≈õci od profilu maszyny
    if is_heavy_machinery:
        cf_warning = HEAVY_SKF_CF_WARNING
        cf_critical = HEAVY_SKF_CF_CRITICAL
        print("     ‚Üí Profil maszyny udarowej AKTYWNY: podwy≈ºszam tolerancjƒô SKF (CF).")
    else:
        cf_warning = SKF_CF_WARNING
        cf_critical = SKF_CF_CRITICAL

    # Oblicz Crest Factor tylko gdy maszyna pracuje W CZASIE PRODUKCJI
    mask_running = (df['vib_rms'] > SKF_VIBRATION_IDLE) & df['is_production']
    df['crest_factor'] = 0.0
    df.loc[mask_running, 'crest_factor'] = (
        df.loc[mask_running, 'vib_max'] / df.loc[mask_running, 'vib_rms']
    )

    # Klasyfikacja SKF
    conditions = [
        ~df['is_production'] | df['is_break'],           # Poza zmianƒÖ / Przerwa
        df['is_warmup'],                                 # Rozgrzewka (maskujemy skoki)
        df['crest_factor'] < SKF_CF_NORMAL,             # Zdrowe ≈Ço≈ºysko
        (df['crest_factor'] >= SKF_CF_NORMAL) &
            (df['crest_factor'] < cf_warning),          # Wczesne zu≈ºycie
        (df['crest_factor'] >= cf_warning) &
            (df['crest_factor'] < cf_critical),         # PostƒôpujƒÖce zu≈ºycie
        df['crest_factor'] >= cf_critical                # Uszkodzenie krytyczne
    ]
    choices = [
        'IDLE',
        'üü¢ MONITORING',
        'üü¢ MONITORING',
        'üü° PLANLEGG SERVICE',
        'üü° PLANLEGG SERVICE',
        'üî¥ KRITISK ALARM'
    ]
    df['skf_status'] = np.select(conditions, choices, default='UNKNOWN')

    return df


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 3: LOGIKA SIEMENS ‚Äî BASELINE DEVIATION (Adaptacyjna Linia Bazowa)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def analyze_siemens_baseline(df: pd.DataFrame) -> pd.DataFrame:
    """
    Siemens Adaptive Baseline ‚Äî banda statystyczna Œº ¬± N√óœÉ.

    Teoria (Siemens MindSphere / AWS Monitron Adaptive Bands):
        Zamiast sztywnego progu "25% odchylenia", obliczamy:

        Œº = ≈õrednia kroczƒÖca RMS z 7 dni produkcji
        œÉ = odchylenie standardowe RMS z tego samego okna

        Alarm WARNING:  RMS > Œº + 2œÉ  lub  RMS < Œº - 2œÉ  (95.4%)
        Alarm CRITICAL: RMS > Œº + 3œÉ  lub  RMS < Œº - 3œÉ  (99.7%)

    Dlaczego to lepsze ni≈º sztywne 25%:
        - Maszyna z naturalnƒÖ zmienno≈õciƒÖ ¬±20% ‚Üí banda szeroka ‚Üí mniej fa≈Çszywych
        - Maszyna stabilna (¬±3%) ‚Üí banda ciasna ‚Üí szybsze wykrycie anomalii
        - System AUTOMATYCZNIE dostosowuje siƒô do charakterystyki maszyny

    Steady-State Filter (filtr stanu ustalonego):
        Alarmy nadajemy TYLKO gdy maszyna jest w stanie ustalonym.
        Startup, rampa, zmiana obciƒÖ≈ºenia ‚Üí ignorujemy.
        Stan ustalony = wsp√≥≈Çczynnik zmienno≈õci (CV) w oknie 30min < 15%.

    Parametr okna (7 dni) wybrany celowo:
        - 7 dni = kompromis rekomendowany przez Siemens dla maszyn ciƒÖg≈Çych
    """
    df = df.copy()

    # ‚îÄ‚îÄ Baseline obliczamy TYLKO na danych produkcyjnych ‚îÄ‚îÄ
    production_rms = df['vib_rms'].copy()
    production_rms[~df['is_production']] = np.nan

    # Œº (≈õrednia) i œÉ (odchylenie standardowe) z okna 7 dni
    df['baseline_7d'] = production_rms.rolling(
        window=SIEMENS_BASELINE_WINDOW,
        min_periods=1
    ).mean()

    df['baseline_7d_std'] = production_rms.rolling(
        window=SIEMENS_BASELINE_WINDOW,
        min_periods=1
    ).std()

    # Bandy statystyczne: Œº ¬± 2œÉ (warning) i Œº ¬± 3œÉ (critical)
    df['band_warning_upper'] = df['baseline_7d'] + SIEMENS_SIGMA_WARNING * df['baseline_7d_std']
    df['band_warning_lower'] = df['baseline_7d'] - SIEMENS_SIGMA_WARNING * df['baseline_7d_std']
    df['band_critical_upper'] = df['baseline_7d'] + SIEMENS_SIGMA_CRITICAL * df['baseline_7d_std']
    df['band_critical_lower'] = df['baseline_7d'] - SIEMENS_SIGMA_CRITICAL * df['baseline_7d_std']

    # ‚îÄ‚îÄ Steady-State Detection (Siemens approach) ‚îÄ‚îÄ
    # CV = œÉ_local / Œº_local ‚Äî je≈õli CV < 15%, maszyna jest stabilna
    local_mean = production_rms.rolling(
        window=SIEMENS_STEADYSTATE_WINDOW, min_periods=3
    ).mean()
    local_std = production_rms.rolling(
        window=SIEMENS_STEADYSTATE_WINDOW, min_periods=3
    ).std()
    df['is_steady_state'] = (
        (local_std / local_mean.replace(0, np.nan)).fillna(1.0)
        < SIEMENS_STEADYSTATE_CV_MAX
    ) & df['is_production']

    # Oblicz odchylenie procentowe (zachowujemy dla raportu / CSV)
    df['baseline_deviation_pct'] = 0.0
    mask_active = (df['baseline_7d'] > SKF_VIBRATION_IDLE) & df['is_production']
    df.loc[mask_active, 'baseline_deviation_pct'] = (
        (df.loc[mask_active, 'vib_rms'] - df.loc[mask_active, 'baseline_7d'])
        / df.loc[mask_active, 'baseline_7d'] * 100
    )

    # ‚îÄ‚îÄ Klasyfikacja Siemens ‚Äî banda statystyczna + steady-state ‚îÄ‚îÄ
    mask_steady_active = mask_active & df['is_steady_state']

    conditions = [
        ~df['is_production'],                                           # Poza zmianƒÖ
        ~mask_active,                                                   # Maszyna wy≈ÇƒÖczona
        df['is_warmup'],                                                # Rozgrzewka maszyny
        ~df['is_steady_state'] & df['is_production'],                  # Stan przej≈õciowy ‚Üí OK
        # Steady-state: por√≥wnaj do band
        mask_steady_active & ~df['is_warmup'] &
            (df['vib_rms'] >= df['band_warning_lower']) &
            (df['vib_rms'] <= df['band_warning_upper']),                # W bandzie ‚Üí OK
        mask_steady_active & ~df['is_warmup'] &
            ((df['vib_rms'] > df['band_warning_upper']) |
             (df['vib_rms'] < df['band_warning_lower'])) &
            (df['vib_rms'] <= df['band_critical_upper']) &
            (df['vib_rms'] >= df['band_critical_lower']),              # Poza 2œÉ
        mask_steady_active & ~df['is_warmup'] &
            ((df['vib_rms'] > df['band_critical_upper']) |
             (df['vib_rms'] < df['band_critical_lower']))              # Poza 3œÉ
    ]
    choices = [
        'IDLE',
        'IDLE',
        'üü¢ MONITORING',          # Rozgrzewka
        'üü¢ MONITORING',          # Stan przej≈õciowy ‚Äî nie alarmuj
        'üü¢ MONITORING',          # WewnƒÖtrz bandy 2œÉ
        'üü° PLANLEGG SERVICE',    # Poza bandƒÖ 2œÉ ‚Äî trend
        'üî¥ KRITISK ALARM'        # Poza bandƒÖ 3œÉ ‚Äî anomalia
    ]
    df['siemens_status'] = np.select(conditions, choices, default='UNKNOWN')

    return df


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 4: LOGIKA AWS MONITRON ‚Äî ANOMALY GRADIENT (Gradient Temperatury)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def analyze_aws_gradient(df: pd.DataFrame, hall_temp: pd.Series = None) -> pd.DataFrame:
    """
    AWS Monitron Gradient Analysis ‚Äî alarmowanie oparte na szybko≈õci zmian.

    Teoria (AWS Monitron Anomaly Detection):
        Nie pytaj "czy temperatura > 100¬∞C?" ‚Äî pytaj "jak SZYBKO ro≈õnie?"

        Gradient = ŒîT / Œît (¬∞C na godzinƒô)

        ≈Åo≈ºysko, kt√≥re nagrza≈Ço siƒô z 40¬∞C do 55¬∞C w ciƒÖgu godziny (+15¬∞C/h)
        jest BARDZIEJ niebezpieczne ni≈º ≈Ço≈ºysko stojƒÖce stabilnie na 80¬∞C.

        Dlaczego? Bo gradient 15¬∞C/h oznacza:
        - Utrata smarowania (olej wyciek≈Ç lub siƒô roz≈Ço≈ºy≈Ç)
        - Zacieranie bie≈ºni
        - Po≈ºar za 2-3 godziny

    Kompensacja temperatury otoczenia:
        Je≈õli dostƒôpne sƒÖ dane z czujnika halowego, gradient jest obliczany
        na podstawie r√≥≈ºnicy (T_≈Ço≈ºysko - T_hala), eliminujƒÖc wp≈Çyw
        pogody i ogrzewania hali na alarmy.

    KLUCZOWE: Ten alarm dzia≈Ça NIEZALE≈ªNIE od warto≈õci bezwzglƒôdnej temperatury.
    Gradient 8¬∞C/h przy 30¬∞C jest TAK SAMO gro≈∫ny jak przy 60¬∞C.
    """
    df = df.copy()

    # Zabezpieczenie przed brakiem temperatury
    if 'temp_mean' not in df.columns:
        # print(f"  [AWS WARN] Brak 'temp_mean', omijam kalkulacje gradientu.")
        df['temp_compensated'] = 0.0
        df['temp_gradient'] = 0.0
        df['temp_gradient_smooth'] = 0.0
        df['temp_gradient_final'] = 0.0
        df['p_aws'] = 0
        df['aws_status'] = 'üü¢ MONITORING (No Temp Data)'
        return df

    # Je≈õli mamy dane halowe, u≈ºyj r√≥≈ºnicy temperatur (kompensacja otoczenia)
    if hall_temp is not None and 'temp_mean' in df.columns:
        # Do≈ÇƒÖcz temperaturƒô hali (nearest match w indeksie czasowym)
        df = df.join(hall_temp, how='left')
        df['hall_temp'] = df['hall_temp'].ffill().bfill()
        df['temp_compensated'] = df['temp_mean'] - df['hall_temp']
        temp_col = 'temp_compensated'
        print("     ‚Üí Kompensacja temperatury otoczenia: AKTYWNA (czujnik halowy)")
    else:
        temp_col = 'temp_mean'
        print("     ‚Üí Kompensacja temperatury otoczenia: BRAK (brak danych halowych)")

    # Oblicz gradient temperatury (¬∞C/h) z oknem 1h
    # U≈ºywamy diff() / diff(periods) = zmiana w oknach 5-min, skalowana do ¬∞C/h
    # 1 godzina = 12 interwa≈Ç√≥w 5-minutowych
    periods_per_hour = int(pd.Timedelta('1h') / pd.Timedelta(AGGREGATION_INTERVAL))

    df['temp_gradient'] = (
        df[temp_col].diff(periods=periods_per_hour)
        / (periods_per_hour * 5 / 60)  # Normalizacja do ¬∞C/h
    )

    # Alternatywnie: gradient kroczƒÖcy z okna 1h (bardziej wyg≈Çadzony)
    df['temp_gradient_smooth'] = df[temp_col].rolling(
        window=periods_per_hour, min_periods=2
    ).apply(
        lambda x: (x.iloc[-1] - x.iloc[0]) / (len(x) * 5 / 60) if len(x) > 1 else 0,
        raw=False
    )

    # U≈ºyj wyg≈Çadzonego gradientu jako g≈Ç√≥wnego
    df['temp_gradient_final'] = df['temp_gradient_smooth'].fillna(df['temp_gradient']).fillna(0)

    # ‚îÄ‚îÄ TYLKO DODATNIE gradienty sƒÖ niebezpieczne ‚îÄ‚îÄ
    # Ujemny gradient = ≈Ço≈ºysko siƒô ch≈Çodzi = DOBRZE.
    # Kalibracja na podstawie prawdziwego po≈ºaru 13.02.2026:
    #   - Normalny gradient produkcyjny: 95th percentyl = +9.9¬∞C/h
    #   - Prawdziwy po≈ºar: +23¬∞C/h ‚Üí +57¬∞C/h
    #   - Pr√≥g CRITICAL: 15¬∞C/h (miƒôdzy 99.9th a po≈ºarem)
    gradient_for_alarm = df['temp_gradient_final'].copy()
    
    # Ekstremalny po≈ºar traktujemy ostro przy po≈ºarze (ponad temp min)
    is_extreme = (df['temp_gradient_final'] >= AWS_GRADIENT_FIRE_EXTREME) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP)
    
    gradient_for_alarm[~df['is_production'] & ~is_extreme] = 0.0    # Poza zmianƒÖ ‚Äî ignoruj
    gradient_for_alarm[df['is_warmup'] & ~is_extreme] = 0.0         # Rozgrzewka ‚Äî ignoruj
    gradient_for_alarm[df['is_break'] & ~is_extreme] = 0.0          # Przerwa ‚Äî ignoruj
    # Zabezpieczenie przed "Cold Startem" - po≈ºar zawsze powoduje wy≈ºszƒÖ temperaturƒô.
    
    conditions = [
        (gradient_for_alarm >= AWS_GRADIENT_FIRE_EXTREME) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP), # üî• EKSTREMALNY PO≈ªAR
        ~df['is_production'] | df['is_break'],                       # Poza zmianƒÖ
        gradient_for_alarm < AWS_GRADIENT_WARNING,                   # Stabilna
        (gradient_for_alarm >= AWS_GRADIENT_WARNING) &
        (gradient_for_alarm < AWS_GRADIENT_CRITICAL),                # Trend grzania
        (gradient_for_alarm >= AWS_GRADIENT_CRITICAL) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP),     # Prawdziwy Krytyczny
        gradient_for_alarm >= AWS_GRADIENT_CRITICAL                  # Alarm zdegradowany przez niskƒÖ temperaturƒô fizycznƒÖ (zimny start)
    ]
    choices = [
        'üî¥üî• BRANN/STOPP',
        'IDLE',
        'üü¢ MONITORING',
        'üü° PLANLEGG SERVICE',
        'üî¥üî• BRANN/STOPP',
        'üü° PLANLEGG SERVICE'                                           # Zimny rozbieg zdegradowany do statusu ≈º√≥≈Çtego!
    ]
    df['aws_status'] = np.select(conditions, choices, default='UNKNOWN')

    return df


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 4B: RANDOM CUT FOREST ‚Äî AWS MONITRON ML
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def analyze_rcf_anomaly(df: pd.DataFrame) -> pd.DataFrame:
    """
    Isolation Forest ‚Äî wielowymiarowa detekcja anomalii (rodzina RCF).

    Teoria (Liu et al., 2008 / AWS Monitron):
        Isolation Forest i Random Cut Forest nale≈ºƒÖ do tej samej rodziny
        algorytm√≥w: tree-based isolation anomaly detection.

        AWS Monitron u≈ºywa RCF (Guha et al., 2016) ‚Äî streamingowa wersja.
        sklearn IsolationForest to batch-wersja z C-optymalizacjƒÖ,
        idealna do analizy historycznych danych CSV.

        Zasada dzia≈Çania (obie wersje):
        1. Buduj losowe drzewa na wielowymiarowych danych
        2. Anomalie = punkty "≈Çatwe do oddzielenia" (kr√≥tka ≈õcie≈ºka w drzewie)
        3. Normalne punkty = g≈Çƒôboko w drzewie (trudne do oddzielenia)

    Cechy wej≈õciowe (4D):
        - vib_rms:              Energia wibracji
        - temp_mean:            Temperatura ≈Ço≈ºyska
        - crest_factor:         Impulsowo≈õƒá (uszkodzenia mechaniczne)
        - temp_gradient_final:  Szybko≈õƒá zmian temperatury

    Trenowanie:
        Tylko na danych PRODUKCYJNYCH.
        Standaryzacja z-score na ka≈ºdej cesze.

    Klasyfikacja:
        Score < P1 (1-ty percentyl) ‚Üí ANOMALIA KRYTYCZNA (najbardziej izolowane)
        Score < P5 (5-ty percentyl) ‚Üí ANOMALIA WARNING
        Reszta ‚Üí MONITORING

    Uwaga: IsolationForest zwraca ujemne score dla anomalii
    (im bardziej ujemny, tym bardziej anomalny).
    """
    from sklearn.ensemble import IsolationForest
    from sklearn.preprocessing import StandardScaler

    df = df.copy()
    df['rcf_score'] = 0.0
    df['rcf_status'] = 'IDLE'

    # Zabezpieczenie przed brakiem temp_mean i temp_gradient_final
    for col in ['temp_mean', 'temp_gradient_final']:
        if col not in df.columns:
            df[col] = 0.0

    # Filtruj: trenujemy TYLKO na produkcji
    prod_mask = df['is_production'] & ~df['is_break']
    prod_df = df[prod_mask].copy()

    if len(prod_df) < 500:
        print("     ‚ö†Ô∏è  Za ma≈Ço danych produkcyjnych dla RCF")
        return df

    # Przygotuj cechy ‚Äî u≈ºywamy tylko tych dostƒôpnych w DF
    actual_features = [f for f in RCF_FEATURES if f in prod_df.columns]
    if not actual_features:
        return df
        
    features = prod_df[actual_features].fillna(0).values
    scaler = StandardScaler()
    features_norm = scaler.fit_transform(features)

    # Buduj Isolation Forest (C-optymalizowany, sekundy zamiast minut)
    print(f"     ‚Üí Budowanie lasu: {RCF_NUM_TREES} drzew √ó {RCF_TREE_SIZE} pr√≥bek...")
    model = IsolationForest(
        n_estimators=RCF_NUM_TREES,
        max_samples=min(RCF_TREE_SIZE, len(features_norm)),
        contamination='auto',  # Automatyczna kalibracja
        random_state=42,
        n_jobs=-1              # U≈ºyj wszystkich rdzeni CPU
    )
    model.fit(features_norm)

    # Score: im bardziej ujemny, tym bardziej anomalny
    scores = model.decision_function(features_norm)

    # Oblicz progi na podstawie rozk≈Çadu (dolne percentyle = anomalie)
    threshold_warning = np.percentile(scores, 100 - RCF_PERCENTILE_WARNING)  # P1
    threshold_critical = np.percentile(scores, 100 - RCF_PERCENTILE_CRITICAL)  # P0.1

    print(f"     ‚Üí Pr√≥g WARNING  (P{100-RCF_PERCENTILE_WARNING:.1f}): {threshold_warning:.3f}")
    print(f"     ‚Üí Pr√≥g CRITICAL (P{100-RCF_PERCENTILE_CRITICAL:.1f}): {threshold_critical:.3f}")
    print(f"     ‚Üí Min score: {scores.min():.3f} | Median: {np.median(scores):.3f}")

    # Wyniki do DF (tylko dla punkt√≥w produkcyjnych)
    prod_indices = prod_df.index
    df.loc[prod_indices, 'rcf_score'] = scores

    # --- NOWO≈öƒÜ: JEDNOSTRONNY FILTR WIBRACYJNY (ANTY-FALSE-POSITIVE DLA POSTOJ√ìW) ---
    # RCF ma tendencjƒô do krzyczenia "ANOMALIA!" gdy maszyna naturalnie zwalnia na koniec zmiany (nag≈Çy zanik wibracji).
    # Chcemy zg≈Çaszaƒá alarmy (Warning/Critical) TYLKO wtedy, gdy RCF znajdzie anomaliƒô ORAZ:
    # 1. Maszyna wibruje silniej ni≈º wynosi jej typowa "zdrowia" ≈õrednia praca.
    # U≈ºywamy tolerancyjnego progu: wibracje muszƒÖ byƒá >= (0.8 * typowa ≈õrednia produkcyjna).
    if 'vib_rms' in prod_df.columns:
        typical_vib = prod_df['vib_rms'].median()
        # Mno≈ºymy przez 0.8, aby pozwoliƒá na alarmy "narastajƒÖce", ale uciƒÖƒá oczywiste puste zera z postoju
        is_vib_spike = df['vib_rms'] >= (typical_vib * 0.8)
    else:
        is_vib_spike = pd.Series(True, index=df.index)

    # Status tylko dla produkcji (poza produkcjƒÖ bƒôdzie IDLE lub nadpisane)
    rcf_status = pd.Series('IDLE', index=df.index)
    
    # Warunkowa klasyfikacja (ni≈ºszy score = anomalia PLUS rosnƒÖce/zgodne wibracje PLUS nie wybieg)
    is_not_rundown = ~df.get('is_rundown', pd.Series(False, index=df.index))
    
    rcf_status[prod_mask] = np.where(
        (scores <= threshold_critical) & is_vib_spike[prod_mask] & is_not_rundown[prod_mask],
        'üî¥ KRITISK ALARM',
        np.where(
            (scores <= threshold_warning) & is_vib_spike[prod_mask] & is_not_rundown[prod_mask],
            'üü° PLANLEGG SERVICE',
            'üü¢ MONITORING'
        )
    )
    df['rcf_status'] = rcf_status

    # Statystyki
    n_warning = (df['rcf_status'] == 'üü° ANOMALIA RCF').sum()
    n_critical = (df['rcf_status'] == 'üî¥ ANOMALIA KRYTYCZNA RCF').sum()
    print(f"     ‚Üí Wykryto: {n_warning} anomalii üü° + {n_critical} anomalii üî¥")

    return df


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 5: FUZJA ALARM√ìW ‚Äî WYNIK KO≈ÉCOWY
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def fuse_alarms(df: pd.DataFrame, is_heavy_machinery: bool = False) -> pd.DataFrame:
    """
    Fuzja alarm√≥w z trzech silnik√≥w diagnostycznych.
    """
    df = df.copy()
    
    # Wyb√≥r persistencji na podstawie klasy
    persistence_required = HEAVY_ALARM_PERSISTENCE_INTERVALS if is_heavy_machinery else ALARM_PERSISTENCE_INTERVALS

    # Zabezpieczenie przed brakujƒÖcymi kolumnami status√≥w
    for col in ['p_skf', 'p_siemens', 'p_aws', 'p_rcf']:
        if col not in df.columns: df[col] = 0
    for col in ['skf_status', 'siemens_status', 'aws_status', 'rcf_status']:
        if col not in df.columns: df[col] = 'IDLE'

    # Mapowanie priorytet√≥w (wy≈ºszy = gorszy)
    priority = {
        'IDLE': 0,
        'üü¢ MONITORING': 1,
        'üü° PLANLEGG SERVICE': 3,
        'üî¥ KRITISK ALARM': 4,
        'üî¥üî• BRANN/STOPP': 5,
        'UNKNOWN': 0
    }

    # Oblicz priorytety per silnik
    df['p_skf'] = df['skf_status'].map(priority).fillna(0)
    df['p_siemens'] = df['siemens_status'].map(priority).fillna(0)
    df['p_aws'] = df['aws_status'].map(priority).fillna(0)
    df['p_rcf'] = df['rcf_status'].map(priority).fillna(0)
    df['max_priority'] = df[['p_skf', 'p_siemens', 'p_aws', 'p_rcf']].max(axis=1)

    # ‚îÄ‚îÄ Alarm Persistence (Debounce) ‚îÄ‚îÄ
    # Dla ka≈ºdego silnika: ile kolejnych interwa≈Ç√≥w alarm jest aktywny?
    # Alarm trwa = priorytet >= 3 (PLANLEGG SERVICE lub wy≈ºej)
    for col in ['p_skf', 'p_siemens', 'p_aws', 'p_rcf']:
        alarm_active = (df[col] >= 3).astype(int)
        # Oblicz ciƒÖg kolejnych jedynek (rolling count z resetem na 0)
        # U≈ºyj cumsum trick: grupa = cumsum(~alarm) ‚Üí count w grupie
        groups = (~alarm_active.astype(bool)).cumsum()
        df[f'{col}_streak'] = alarm_active.groupby(groups).cumsum()

    # Persistence: alarm potwierdzony dopiero po N kolejnych interwa≈Çach
    for col, status_col in [('p_skf', 'skf_status'),
                            ('p_siemens', 'siemens_status'),
                            ('p_aws', 'aws_status'),
                            ('p_rcf', 'rcf_status')]:
        # Ekstremalny po≈ºar wymaga potƒô≈ºnego gradientu I potwierdzenia, ≈ºe to nie jest zimny start z mrozu.
        is_extreme_fire = False
        if 'temp_gradient_final' in df.columns and 'temp_mean' in df.columns:
            is_extreme_fire = (df['temp_gradient_final'] >= AWS_GRADIENT_FIRE_EXTREME) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP)
        
        # BRANN/STOPP (priorytet 5) ‚Äî wym√≥g potwierdzenia
        # CHYBA ≈ªE JEST TO EKSTREMALNY PO≈ªAR (kt√≥ry nie zmarz≈Ç) - wtedy bypass debouncingu (persistence = 0)
        is_fire_not_persistent = (
            (df[col] >= 5) &
            (df[f'{col}_streak'] < ALARM_PERSISTENCE_FIRE) &
            ~is_extreme_fire
        )
        # Zwyk≈Çe alarmy (priorytet 3-4) ‚Äî pe≈Çna persistence 
        # Zmieniono: alarmy nie s≈° ju≈º kasowane do statusu ZIELONEGO,
        # Je≈ºeli alarm (np p=4) nie ma persistence, pr√≥bujemy zachowaƒá chocia≈º p=3 je≈õli pod spodem te≈º krzyczy algorytm
        is_alarm_not_persistent = (
            (df[col] >= 3) &
            (df[col] < 5) &
            (df[f'{col}_streak'] < persistence_required)
        )
        
        # Degradacja: zamiast na ≈õlepo wrzucaƒá üü¢ MONITORING (p=1), 
        # zrzucamy nietrwa≈Çe p>=4 do p=3 (SERVICE), a nietrwa≈Çe p=3 do p=1
        df.loc[is_fire_not_persistent, col] = 4
        df.loc[is_fire_not_persistent, status_col] = 'üî¥ KRITISK ALARM'
        
        unpersisted_crit = is_alarm_not_persistent & (df[col] == 4)
        df.loc[unpersisted_crit, col] = 3
        df.loc[unpersisted_crit, status_col] = 'üü° PLANLEGG SERVICE'
        
        unpersisted_warn = is_alarm_not_persistent & (df[col] == 3)
        df.loc[unpersisted_warn, col] = 1
        df.loc[unpersisted_warn, status_col] = 'üü¢ MONITORING'

    # Przelicz max_priority po debounce
    df['max_priority'] = df[['p_skf', 'p_siemens', 'p_aws', 'p_rcf']].max(axis=1)

    # Wynik ko≈Ñcowy
    conditions = [
        df['max_priority'] == 0,
        df['max_priority'] == 1,
        df['max_priority'].isin([2, 3]),
        df['max_priority'] == 4,
        df['max_priority'] >= 5
    ]
    choices = [
        'IDLE',
        'üü¢ MONITORING',
        'üü° PLANLEGG SERVICE',
        'üî¥ KRITISK ALARM',
        'üî¥üî• BRANN/STOPP'
    ]
    df['FINAL_VERDICT'] = np.select(conditions, choices, default='UNKNOWN')

    # ≈πr√≥d≈Ço alarmu
    def get_alarm_source(row):
        sources = []
        if row['p_skf'] >= 3:
            sources.append('SKF')
        if row['p_siemens'] >= 3:
            sources.append('Siemens')
        if row['p_aws'] >= 3:
            sources.append('AWS')
        if row['p_rcf'] >= 3:
            sources.append('RCF')
        return '+'.join(sources) if sources else '-'

    df['alarm_source'] = df.apply(get_alarm_source, axis=1)

    return df


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 6: HEALTH INDEX + PRAWDOPODOBIE≈ÉSTWO AWARII
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def calculate_health_index(df: pd.DataFrame) -> pd.DataFrame:
    """
    Composite Health Index (0-100%) + P(awaria w ciƒÖgu 24h).

    Teoria (ISO 13381-1 / Augury / SparkCognition):
        Health Index ≈ÇƒÖczy wyniki 4 silnik√≥w w jeden ciƒÖg≈Çy wska≈∫nik.

        P(awaria) ‚Äî sigmoidalna konwersja HI na prawdopodobie≈Ñstwo.
        Kalibracja na prawdziwym po≈ºarze 13.02.2026:
          - HI=100% ‚Üí P‚âà1%   (≈Ço≈ºysko zdrowe)
          - HI=50%  ‚Üí P‚âà15%  (wczesne zu≈ºycie)
          - HI=20%  ‚Üí P‚âà75%  (zaawansowane uszkodzenie)
          - HI=0%   ‚Üí P‚âà99%  (awaria nieunikniona)
    """
    df = df.copy()

    # ‚îÄ‚îÄ 1. Normalizacja komponent√≥w do skali 0-100% ‚îÄ‚îÄ

    # --- Komponent wibracyjny (Siemens baseline) ---
    # KLUCZOWA POPRAWKA: vib_rms ‚âà 0 przy wysokiej temp = ≈Ço≈ºysko siƒô zaklinowa≈Ço!
    dev_abs = df['baseline_deviation_pct'].abs().clip(0, 200)
    hi_vib = (1 - dev_abs / 200) * 100
    # Zakleszczenie = vib prawie zero, ALE temp ro≈õnie drastycznie szybciej ni≈º powinna!
    # U≈ºywamy wyliczonego gradientu temp - je≈ºeli wa≈Ç stoi (vib_rms < 0.01) ale grzeje siƒô tempem > 12C/h
    # Oznacza to potƒô≈ºne zaci≈õniƒôcie pasa / spalanie cewek silnika!
    seized_mask = (df['vib_rms'] < 0.01) & (df['temp_gradient_final'] > 12.0)
    hi_vib[seized_mask] = 0.0

    # --- Komponent gradientu temperatury (AWS) ---
    grad_pos = df['temp_gradient_final'].clip(lower=0)
    hi_grad = (1 - grad_pos / AWS_GRADIENT_CRITICAL).clip(0, 1) * 100
    # Desensytyzacja rozgrzewki: podczas warmup gradient jest naturalny
    if 'is_warmup' in df.columns:
        hi_grad[df['is_warmup']] = hi_grad[df['is_warmup']] * 0.5 + 50

    # --- Komponent absolutnej temperatury ---
    # > 55¬∞C = zaczyna byƒá niebezpieczne, > 90¬∞C = krytyczne
    TEMP_SAFE = 55.0
    TEMP_CRITICAL = 90.0
    hi_abs_temp = ((TEMP_CRITICAL - df['temp_mean']) / (TEMP_CRITICAL - TEMP_SAFE)).clip(0, 1) * 100

    # --- NOWY: Komponent ISO 10816-1 (Absolutne normy wibracji) ---
    # Chroni przed "ska≈ºonym baseline" ‚Äî je≈õli maszyna wibruje ≈∫le od poczƒÖtku,
    # ISO to wychwyci, nawet je≈õli Siemens baseline m√≥wi ≈ºe jest "normalnie".
    # Klasa I: <0.71=100%, 1.8=50%, 4.5=0%
    if df['vib_rms'].max() > 0:
        hi_iso = np.interp(
            df['vib_rms'],
            [0, ISO_VIB_ZONE_A_B, ISO_VIB_ZONE_B_C, ISO_VIB_ZONE_C_D],
            [100, 100, 50, 0]
        )
    else:
        hi_iso = 100.0

    # --- Komponent CF (SKF) ---
    cf_norm = ((df['crest_factor'] - 1) / (SKF_CF_CRITICAL - 1)).clip(0, 1)
    hi_cf = (1 - cf_norm) * 100

    # --- Komponent RCF (Isolation Forest) ---
    rcf_norm = ((df['rcf_score'] + 0.2) / 0.3).clip(0, 1)
    hi_rcf = rcf_norm * 100

    # ‚îÄ‚îÄ 2. Wa≈ºony Health Index ‚îÄ‚îÄ
    # Wagi rebalansowane dla uwzglƒôdnienia ISO (20%):
    W_VIB_REL = 0.20    # Siemens (relatywny do historii)
    W_VIB_ABS = 0.20    # ISO (absolutny do norm)
    W_GRAD = 0.20       # Gradient temperatury
    W_ABS_TEMP = 0.15   # Absolutna temperatura
    W_CF = 0.10         # Crest Factor
    W_RCF = 0.15        # Isolation Forest (wielowymiarowy)

    df['health_index'] = (
        W_VIB_REL * hi_vib +
        W_VIB_ABS * hi_iso +
        W_GRAD * hi_grad +
        W_ABS_TEMP * hi_abs_temp +
        W_CF * hi_cf +
        W_RCF * hi_rcf
    ).clip(0, 100)

    # Hard override: fizycznie niebezpieczne warunki
    # 1. Temperatura > 80¬∞C = max HI = 30%
    df.loc[df['temp_mean'] > 80, 'health_index'] = df.loc[
        df['temp_mean'] > 80, 'health_index'].clip(upper=30)
    # 2. Gradient > 20¬∞C/h = max HI = 25%
    df.loc[grad_pos > 20, 'health_index'] = df.loc[
        grad_pos > 20, 'health_index'].clip(upper=25)
    # 3. Zakleszczenie (vib‚âà0 + temp>40¬∞C) = max HI = 15%
    df.loc[seized_mask, 'health_index'] = df.loc[
        seized_mask, 'health_index'].clip(upper=15)

    df.loc[~df['is_production'], 'health_index'] = np.nan

    # ‚îÄ‚îÄ 3. Trend HI (2h okno = 24 interwa≈Çy) ‚îÄ‚îÄ
    df['hi_trend'] = df['health_index'].diff(periods=24)

    # ‚îÄ‚îÄ 4. RUL (Remaining Useful Life) Prediction ‚îÄ‚îÄ
    # Przewidujemy czas do osiƒÖgniƒôcia HI = 15% (pr√≥g krytyczny)
    # RUL [h] = (Current_HI - Critical_HI) / (Degradation_Rate_per_hour)
    CRITICAL_HI = 15.0
    df['rul_hours'] = np.nan
    
    # Delta HI na godzinƒô (12 interwa≈Ç√≥w po 5 min)
    hi_rate_per_hour = df['health_index'].diff(periods=12)
    
    # Oblicz RUL tylko gdy zdrowie SPADA (rate < 0)
    degrading = (hi_rate_per_hour < -0.1) & (df['health_index'] > CRITICAL_HI)
    df.loc[degrading, 'rul_hours'] = (
        (df.loc[degrading, 'health_index'] - CRITICAL_HI) / 
        (-hi_rate_per_hour.loc[degrading])
    ).clip(0, 168) # Max 1 tydzie≈Ñ prognozy

    # ‚îÄ‚îÄ 5. P(awaria) ‚Äî sigmoid z recalibrowanymi parametrami ‚îÄ‚îÄ
    # Steilsza krzywa: k=10 (by≈Ço 8), midpoint x0=0.45 (by≈Ço 0.35)
    # Efekt: P ro≈õnie szybciej gdy HI spada poni≈ºej 45%
    SIGMOID_K = 10
    SIGMOID_X0 = 0.45
    hi_norm = df['health_index'].fillna(100) / 100
    base_p = 1 / (1 + np.exp(-SIGMOID_K * (SIGMOID_X0 - hi_norm)))

    # Silniejszy modyfikator trendu: spadajƒÖcy HI ‚Üí +30% P (by≈Ço +20%)
    trend_mod = (-df['hi_trend'].fillna(0) / 100).clip(0, 0.30)
    df['failure_probability'] = (base_p + trend_mod).clip(0, 0.99) * 100
    df.loc[~df['is_production'], 'failure_probability'] = np.nan

    # ‚îÄ‚îÄ 5. Klasyfikacja ryzyka ‚îÄ‚îÄ
    conditions = [
        ~df['is_production'],
        df['failure_probability'] <= 5,
        (df['failure_probability'] > 5) & (df['failure_probability'] <= 25),
        (df['failure_probability'] > 25) & (df['failure_probability'] <= 60),
        df['failure_probability'] > 60
    ]
    choices = [
        'IDLE',
        'üü¢ NISKIE (0-5%)',
        'üü° UMIARKOWANE (5-25%)',
        'üü† WYSOKIE (25-60%)',
        'üî¥ KRYTYCZNE (>60%)'
    ]
    df['risk_level'] = np.select(conditions, choices, default='UNKNOWN')

    return df


def print_health_report(df: pd.DataFrame):
    """Drukuj raport Health Index z prawdopodobie≈Ñstwem awarii."""
    prod = df[df['is_production'] == True].copy()
    if len(prod) == 0:
        return

    print(f"\n{'‚ïê' * 80}")
    print(f"  üè• HEALTH INDEX ‚Äî PRAWDOPODOBIE≈ÉSTWO AWARII")
    print(f"{'‚ïê' * 80}")

    # Ostatni znany stan
    last = prod.iloc[-1]
    
    # Formatowanie RUL
    rul_text = "STABILNY"
    if not np.isnan(last['rul_hours']):
        if last['rul_hours'] < 1:
            rul_text = f"üî¥ KATASTROFA (< 1h!)"
        elif last['rul_hours'] < 24:
            rul_text = f"üü† {last['rul_hours']:.1f} h (Dzi≈õ!)"
        else:
            rul_text = f"üü° {last['rul_hours']/24:.1f} dni"

    print(f"\n  üìç Ostatni pomiar: {prod.index[-1]}")
    print(f"     Health Index:                  {last['health_index']:.0f}%")
    print(f"     P(awaria w ciƒÖgu 24h):         {last['failure_probability']:.1f}%")
    print(f"     Trend (ostatnie 2h):           {last['hi_trend']:+.1f}%" if not np.isnan(last['hi_trend']) else f"     Trend:                         brak danych")
    print(f"     RUL (Prognoza czasu pracy):    {rul_text}")
    print(f"     Poziom ryzyka:                 {last['risk_level']}")

    # Rozk≈Çad ryzyka
    print(f"\n  üìä Rozk≈Çad ryzyka (ca≈Çy okres):")
    for level in ['üü¢ NISKIE (0-5%)', 'üü° UMIARKOWANE (5-25%)',
                  'üü† WYSOKIE (25-60%)', 'üî¥ KRYTYCZNE (>60%)']:
        count = (df['risk_level'] == level).sum()
        pct = count / len(prod) * 100
        print(f"     {level}: {count:,} ({pct:.1f}%)")

    # Top 10
    print(f"\n  üîù TOP 10 ‚Äî Najwy≈ºsze P(awaria) / Najni≈ºszy RUL:")
    top = prod.nlargest(10, 'failure_probability')
    for idx, row in top.iterrows():
        rt = f"{row['rul_hours']:.1f}h" if not np.isnan(row['rul_hours']) else "---"
        print(f"     {idx}  HI={row['health_index']:4.0f}%  "
              f"P={row['failure_probability']:5.1f}%  "
              f"RUL={rt:>6}  "
              f"T={row['temp_mean']:5.1f}¬∞")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MODU≈Å 7: RAPORT BIZNESOWY
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def print_header():
    """Wydrukuj nag≈Ç√≥wek raportu."""
    print("\n")
    print("‚ïî" + "‚ïê" * 96 + "‚ïó")
    print("‚ïë  DIAGNOSTIKKRAPPORT ‚Äî LAGERMONITORINGSSYSTEM" + " " * 50 + "‚ïë")
    print("‚ïë  Metode: SKF Crest Factor + Siemens Baseline + AWS Monitron Gradient" + " " * 24 + "‚ïë")
    print("‚ïë  Standard: ISO 13373-1 / IEC 61508 (SIL-2 alarm fusion)" + " " * 39 + "‚ïë")
    print("‚ï†" + "‚ïê" * 96 + "‚ï£")
    print("‚ïë  ALARMFORKLARING:" + " " * 78 + "‚ïë")
    print("‚ïë    üü¢ MONITORING      ‚Äî Stabil drift, ingen handling n√∏dvendig" + " " * 29 + "‚ïë")
    print("‚ïë    üü° PLANLEGG SERVICE ‚Äî Planlegg lagerskifte innen 2-4 uker" + " " * 30 + "‚ïë")
    print("‚ïë    üî¥ BRANN/STOPP      ‚Äî STOPP LINJEN! Risiko for brann/havari" + " " * 25 + "‚ïë")
    print("‚ïö" + "‚ïê" * 96 + "‚ïù")


def print_summary_stats(df: pd.DataFrame):
    """Wydrukuj podsumowanie statystyczne."""
    total = len(df)
    idle = len(df[df['FINAL_VERDICT'] == 'IDLE'])
    ok = len(df[df['FINAL_VERDICT'] == 'üü¢ MONITORING'])
    warn = len(df[df['FINAL_VERDICT'] == 'üü° PLANLEGG SERVICE'])
    crit = len(df[df['FINAL_VERDICT'].str.contains('üî¥', na=False)])

    print(f"\n{'‚îÄ' * 80}")
    print(f"  üìä STATISTISK OPPSUMMERING ({total} 5-minutters intervaller)")
    print(f"{'‚îÄ' * 80}")
    print(f"  ‚öôÔ∏è  IDLE (maskin av): {idle:>6}  ({idle/total*100:5.1f}%)")
    print(f"  üü¢ MONITORING (stabil):       {ok:>6}  ({ok/total*100:5.1f}%)")
    print(f"  üü° PLANLEGG SERVICE (trend):   {warn:>6}  ({warn/total*100:5.1f}%)")
    print(f"  üî¥ KRITISK ALARM / BRANN:      {crit:>6}  ({crit/total*100:5.1f}%)")
    print(f"{'‚îÄ' * 80}")

    # Temperatura
    print(f"\n  üå°Ô∏è  TEMPERATURA ≈ÅO≈ªYSKA:")
    print(f"      Min: {df['temp_mean'].min():6.1f}¬∞C | "
          f"≈örednia: {df['temp_mean'].mean():6.1f}¬∞C | "
          f"Max: {df['temp_mean'].max():6.1f}¬∞C")

    # Wibracje
    running = df[df['vib_rms'] > SKF_VIBRATION_IDLE]
    if len(running) > 0:
        print(f"\n  üì≥ WIBRACJE (gdy maszyna pracuje):")
        print(f"      RMS Min: {running['vib_rms'].min():.3f}g | "
              f"≈örednia: {running['vib_rms'].mean():.3f}g | "
              f"Max: {running['vib_rms'].max():.3f}g")
        print(f"      Crest Factor Min: {running['crest_factor'].min():.2f} | "
              f"≈öredni: {running['crest_factor'].mean():.2f} | "
              f"Max: {running['crest_factor'].max():.2f}")

    # Gradient
    print(f"\n  üìà GRADIENT TEMPERATURY:")
    print(f"      Max wzrost: {df['temp_gradient_final'].max():+.1f}¬∞C/h | "
          f"Max spadek: {df['temp_gradient_final'].min():+.1f}¬∞C/h")


def print_alarm_events(df: pd.DataFrame):
    """Wydrukuj szczeg√≥≈ÇowƒÖ listƒô zdarze≈Ñ alarmowych."""
    alarms = df[df['FINAL_VERDICT'].str.contains('SERVICE|ALARM|BRANN', na=False)].copy()

    if len(alarms) == 0:
        print("\n  ‚úÖ BRAK ALARM√ìW ‚Äî Maszyna pracuje w normie przez ca≈Çy analizowany okres.")
        return

    print(f"\n{'‚ïê' * 100}")
    print(f"  ‚ö†Ô∏è  ZDARZENIA ALARMOWE ({len(alarms)} interwa≈Ç√≥w)")
    print(f"{'‚ïê' * 100}")
    print(f"  {'Czas':<22} ‚îÇ {'Temp':>6} ‚îÇ {'Vib_RMS':>7} ‚îÇ {'CF':>5} ‚îÇ "
          f"{'Œî%Baza':>7} ‚îÇ {'ŒîT/h':>6} ‚îÇ {'≈πr√≥d≈Ço':>8} ‚îÇ Status")
    print(f"  {'‚îÄ' * 22}‚îÄ‚îº‚îÄ{'‚îÄ' * 6}‚îÄ‚îº‚îÄ{'‚îÄ' * 7}‚îÄ‚îº‚îÄ{'‚îÄ' * 5}‚îÄ‚îº‚îÄ"
          f"{'‚îÄ' * 7}‚îÄ‚îº‚îÄ{'‚îÄ' * 6}‚îÄ‚îº‚îÄ{'‚îÄ' * 8}‚îÄ‚îº‚îÄ{'‚îÄ' * 30}")

    # Grupuj ciƒÖg≈Çe zdarzenia alarmowe aby nie zalewaƒá konsoli
    # Poka≈º pierwsze i ostatnie zdarzenie z ka≈ºdej grupy
    prev_verdict = None
    group_start = None
    group_count = 0

    for idx, row in alarms.iterrows():
        current_verdict = row['FINAL_VERDICT']

        if current_verdict != prev_verdict:
            # Nowa grupa alarmowa
            if group_count > 2 and prev_verdict is not None:
                print(f"  {'... (' + str(group_count - 2) + ' wiƒôcej)':<22} ‚îÇ {'':>6} ‚îÇ "
                      f"{'':>7} ‚îÇ {'':>5} ‚îÇ {'':>7} ‚îÇ {'':>6} ‚îÇ {'':>8} ‚îÇ")

            timestamp_str = idx.strftime('%Y-%m-%d %H:%M')
            print(f"  {timestamp_str:<22} ‚îÇ {row['temp_mean']:>5.1f}¬∞ ‚îÇ "
                  f"{row['vib_rms']:>7.3f} ‚îÇ {row['crest_factor']:>5.2f} ‚îÇ "
                  f"{row['baseline_deviation_pct']:>+6.0f}% ‚îÇ "
                  f"{row['temp_gradient_final']:>+5.1f}¬∞ ‚îÇ "
                  f"{row['alarm_source']:>8} ‚îÇ {current_verdict}")
            group_start = idx
            group_count = 1
            prev_verdict = current_verdict
        else:
            group_count += 1
            if group_count <= 2:
                timestamp_str = idx.strftime('%Y-%m-%d %H:%M')
                print(f"  {timestamp_str:<22} ‚îÇ {row['temp_mean']:>5.1f}¬∞ ‚îÇ "
                      f"{row['vib_rms']:>7.3f} ‚îÇ {row['crest_factor']:>5.2f} ‚îÇ "
                      f"{row['baseline_deviation_pct']:>+6.0f}% ‚îÇ "
                      f"{row['temp_gradient_final']:>+5.1f}¬∞ ‚îÇ "
                      f"{row['alarm_source']:>8} ‚îÇ {current_verdict}")

    # Ostatnia grupa
    if group_count > 2:
        print(f"  {'... (' + str(group_count - 2) + ' wiƒôcej)':<22} ‚îÇ {'':>6} ‚îÇ "
              f"{'':>7} ‚îÇ {'':>5} ‚îÇ {'':>7} ‚îÇ {'':>6} ‚îÇ {'':>8} ‚îÇ")


def print_recommendations(df: pd.DataFrame):
    """Wydrukuj rekomendacje dzia≈Ça≈Ñ na podstawie wynik√≥w analizy."""
    alarms = df[df['FINAL_VERDICT'].str.contains('SERVICE|ALARM|BRANN', na=False)]

    print(f"\n{'‚ïê' * 80}")
    print("  üìã REKOMENDACJE DLA ZARZƒÑDU / KIEROWNIKA UR")
    print(f"{'‚ïê' * 80}")

    if len(alarms) == 0:
        print("  ‚úÖ Brak wymaganych dzia≈Ça≈Ñ. Kontynuowaƒá monitoring.")
        return

    has_fire = df['FINAL_VERDICT'].str.contains('BRANN', na=False).any()
    has_critical = df['FINAL_VERDICT'].str.contains('KRITISK', na=False).any()
    has_service = df['FINAL_VERDICT'].str.contains('SERVICE', na=False).any()

    rec_num = 1
    if has_fire:
        print(f"\n  üî¥ REKOMENDACJA {rec_num}: NATYCHMIASTOWE ZATRZYMANIE")
        print(f"     Wykryto krytyczny gradient temperatury (>{AWS_GRADIENT_CRITICAL}¬∞C/h).")
        print(f"     Uzasadnienie: Zgodnie z AWS Monitron methodology, szybki wzrost")
        print(f"     temperatury wskazuje na utratƒô smarowania lub zacieranie (üî¥üî• BRANN/STOPP).")
        print(f"     RYZYKO: Po≈ºar ≈Ço≈ºyska w ciƒÖgu 1-3 godzin bez interwencji.")
        print(f"     AKCJA: Zatrzymaj liniƒô. Sprawd≈∫ smarowanie i stan bie≈ºni.")
        rec_num += 1

    if has_critical:
        print(f"\n  üî¥ REKOMENDACJA {rec_num}: WYMIANA ≈ÅO≈ªYSKA W CIƒÑGU 48H")
        print(f"     Wykryto krytyczne odchylenie od normy pracy lub wysoki Crest Factor.")
        print(f"     Uzasadnienie: Analiza SKF/Siemens wskazuje na zaawansowane")
        print(f"     uszkodzenie mechaniczne bie≈ºni lub kulek ≈Ço≈ºyska.")
        print(f"     AKCJA: Zam√≥w ≈Ço≈ºysko. Zaplanuj wymianƒô na najbli≈ºszy przest√≥j.")
        rec_num += 1

    if has_service:
        print(f"\n  üü° REKOMENDACJA {rec_num}: PLANOWANY SERWIS (2-4 TYGODNIE)")
        print(f"     Wykryto trend wzrostowy wibracji lub temperatury.")
        print(f"     Uzasadnienie: Siemens Baseline Deviation wskazuje na")
        print(f"     postƒôpujƒÖce zu≈ºycie (üü° PLANLEGG SERVICE).")
        print(f"     AKCJA: Zam√≥w czƒô≈õci. Zaplanuj wymianƒô w ramach planowego przestoju.")
        rec_num += 1

    # Podsumowanie koszt√≥w
    print(f"\n  üí∞ UZASADNIENIE EKONOMICZNE:")
    print(f"     Koszt planowanej wymiany ≈Ço≈ºyska:     ~2,000-5,000 PLN")
    print(f"     Koszt nieplanowanego przestoju (1h):   ~10,000-30,000 PLN")
    print(f"     Koszt po≈ºaru i odbudowy linii:         ~500,000-2,000,000 PLN")
    print(f"     ‚Üí Prewencja jest 100-400√ó ta≈Ñsza ni≈º awaria.")


def export_results(df: pd.DataFrame, output_path: str):
    """Eksportuj wyniki analizy do CSV."""
    export_cols = [
        'sn',
        'is_production', 'is_break', 'is_warmup',
        'temp_mean', 'vib_rms', 'vib_max', 'crest_factor', 'avg_line_vibration',
        'baseline_7d', 'baseline_deviation_pct',
        'temp_gradient_final',
        'rcf_score',
        'health_index', 'failure_probability', 'rul_hours', 'risk_level',
        'skf_status', 'siemens_status', 'aws_status', 'rcf_status',
        'FINAL_VERDICT', 'alarm_source'
    ]
    existing_cols = [c for c in export_cols if c in df.columns]
    df[existing_cols].to_csv(output_path, sep=';', encoding='utf-8-sig')
    print(f"\n  üíæ Wyniki zapisane do: {output_path}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MAIN ‚Äî URUCHOMIENIE ANALIZY
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    """
    G≈Ç√≥wna funkcja analizy. Uruchamia kolejno:
    1. ≈Åadowanie danych
    2. Agregacja 5-minutowa
    3. Analiza SKF (Crest Factor)
    4. Analiza Siemens (Baseline Deviation)
    5. Analiza AWS Monitron (Temperature Gradient)
    6. Analiza RCF (Random Cut Forest ‚Äî ML)
    7. Fuzja alarm√≥w
    8. Raport biznesowy
    """
    print("‚ïî" + "‚ïê" * 70 + "‚ïó")
    print("‚ïë  URUCHAMIANIE SYSTEMU DIAGNOSTYCZNEGO" + " " * 32 + "‚ïë")
    print("‚ïë  Bearing Condition Monitor v2.0 (z Random Cut Forest)" + " " * 16 + "‚ïë")
    print("‚ïö" + "‚ïê" * 70 + "‚ïù")

    # ≈öcie≈ºki do plik√≥w
    script_dir = os.path.dirname(os.path.abspath(__file__))
    file_paths = {
        "OV": "dane_lozysko_projektOV.csv",
        "OH": "dane_lozysko_projektOH.csv",
        "NH": "dane_lozysko_projektNH.csv",
        "NV": "dane_lozysko_projektNV.csv"
    }
    hall_file = os.path.join(script_dir, 'dane_hala_projekt.csv')

    # ‚îÄ‚îÄ Krok 1: ≈Åadowanie danych ‚îÄ‚îÄ
    print("\nüì• KROK 1/9: ≈Åadowanie danych z czujnik√≥w IoT (Sklejenie z 4 wrzecion)...")
    
    dfs = []
    for label, filename in file_paths.items():
        filepath = os.path.join(script_dir, filename)
        if os.path.exists(filepath):
            df_part = load_sensor_data(filepath)
            
            # Wzbogacenie identyfikatora czujnika o pozycjƒô na maszynie dla czytelnych raport√≥w
            df_part['sn'] = df_part['sn'].astype(str) + f" ({label})"
            dfs.append(df_part)
        else:
            print(f"  ‚ö†Ô∏è  Brak pliku: {filename}")
            
    if not dfs:
        print("‚ùå Brak jakichkolwiek plik√≥w z danymi ≈Ço≈ºysk! Zatrzymanie analizy.")
        return
        
    bearing_raw = pd.concat(dfs, ignore_index=True)

    hall_temp = None
    if os.path.exists(hall_file):
        hall_raw = load_sensor_data(hall_file)
        hall_temp_df = prepare_hall_data(hall_raw)
        hall_temp = hall_temp_df['hall_temp'] if isinstance(hall_temp_df, pd.DataFrame) else hall_temp_df
    else:
        print("  ‚ö†Ô∏è  Brak danych halowych ‚Äî gradient bez kompensacji otoczenia")

    # ‚îÄ‚îÄ Krok 2: Przygotowanie danych per silnik i korelacja (Saga) ‚îÄ‚îÄ
    print(f"\nüìä KROK 2/9: Agregacja do interwa≈Ç√≥w {AGGREGATION_INTERVAL} i grupowanie po czujnikach...")
    aggregated_sensors = {}
    for sn, sensor_data in bearing_raw.groupby('sn'):
        print(f"     ‚Üí Przetwarzanie napƒôdu SN: {sn}...")
        df_sensor = prepare_bearing_data(sensor_data)
        df_sensor['sn'] = sn
        aggregated_sensors[sn] = df_sensor

    if not aggregated_sensors:
        print("Brak poprawnych danych do analizy.")
        return

    # Oblicz wsp√≥lnƒÖ wibracjƒô (Avg Line Vibration)
    all_vib = pd.DataFrame({sn: df['vib_rms'] for sn, df in aggregated_sensors.items()})
    avg_line_vib = all_vib.mean(axis=1)

    # ‚îÄ‚îÄ Analiza dla ka≈ºdego silnika niezale≈ºnie ‚îÄ‚îÄ
    final_dfs = []
    
    for sn, df_sensor in aggregated_sensors.items():
        print(f"\n{'‚ïê' * 80}")
        print(f"  üîÑ ROZPOCZƒòCIE ANALIZY DLA SILNIKA / CZUJNIKA SN: {sn}")
        print(f"{'‚ïê' * 80}")
        df = df_sensor.copy()
        
        # Wstrzyknij 'avg_line_vibration' dla tego silnika
        df['avg_line_vibration'] = avg_line_vib
        
        # --- SPRAWDZENIE PROFILU MASZYNY (HEAVY IMPACT) ---
        is_heavy_machinery = any(keyword.upper() in str(sn).upper() for keyword in HEAVY_KEYWORDS)
        if is_heavy_machinery:
            print("  ‚ö†Ô∏è DETEKCJA PROFILU CIƒò≈ªKIEGO: Wykryto rƒôbaka/QSS. Ograniczam czu≈Ço≈õƒá wibracyjnƒÖ i persystencjƒô.")
        
        # ‚îÄ‚îÄ Krok 3: SKF Crest Factor ‚îÄ‚îÄ
        print("üîß KROK 3/9: Analiza SKF ‚Äî Crest Factor (uszkodzenia mechaniczne)...")
        df = analyze_skf_crest_factor(df, is_heavy_machinery)

        # ‚îÄ‚îÄ Krok 4: Siemens Baseline ‚îÄ‚îÄ
        print("üìê KROK 4/9: Analiza Siemens ‚Äî Adaptive Baseline (banda Œº¬±2œÉ)...")
        df = analyze_siemens_baseline(df)

        # ‚îÄ‚îÄ Krok 5: AWS Gradient ‚îÄ‚îÄ
        print("üå°Ô∏è  KROK 5/9: Analiza AWS Monitron ‚Äî Gradient temperatury...")
        df = analyze_aws_gradient(df, hall_temp)

        # ‚îÄ‚îÄ Krok 6: Random Cut Forest ‚îÄ‚îÄ
        print("üå≤ KROK 6/9: Analiza RCF ‚Äî Random Cut Forest (wielowymiarowy ML)...")
        df = analyze_rcf_anomaly(df)

        # ‚îÄ‚îÄ Krok 7: Fuzja alarm√≥w ‚îÄ‚îÄ
        print("‚ö° KROK 7/9: Fuzja alarm√≥w (worst-case, SIL-2 + persistence)...")
        df = fuse_alarms(df, is_heavy_machinery)

        # ‚îÄ‚îÄ Krok 8: Health Index + P(awaria) ‚îÄ‚îÄ
        print("üè• KROK 8/9: Health Index + P(awaria w ciƒÖgu 24h)...")
        df = calculate_health_index(df)
        
        final_dfs.append(df)
    
    # Z≈ÇƒÖczenie wynik√≥w do raportu
    all_results_df = pd.concat(final_dfs).sort_index()

    # ‚îÄ‚îÄ Krok 9: Raport (Wersja Zbiorcza i Osobna) ‚îÄ‚îÄ
    print("\nüìã KROK 9/9: Generowanie raportu...")
    print_header()
    
    for sn, df_sensor_final in zip(aggregated_sensors.keys(), final_dfs):
        print(f"\n{'=' * 80}")
        print(f"  RAPORT WYNIKOWY DLA SN: {sn}")
        print(f"{'=' * 80}")
        print_summary_stats(df_sensor_final)
        print_alarm_events(df_sensor_final)
        print_health_report(df_sensor_final)
        print_recommendations(df_sensor_final)

    # ‚îÄ‚îÄ Eksport wynik√≥w ‚îÄ‚îÄ
    output_path = os.path.join(script_dir, 'raport_diagnostyczny.csv')
    export_results(all_results_df, output_path)

    print(f"\n{'‚ïê' * 80}")
    print(f"  ‚úÖ ANALIZA KASKADOWA ZAKO≈ÉCZONA")
    print(f"     Przeanalizowano silniki: {list(aggregated_sensors.keys())}")
    print(f"     ≈ÅƒÖcznie interwa≈Ç√≥w: {len(all_results_df)}")
    print(f"     Zakres dat: {all_results_df.index.min()} ‚Äî {all_results_df.index.max()}")
    print(f"{'‚ïê' * 80}\n")

    return all_results_df


if __name__ == '__main__':
    result = main()
