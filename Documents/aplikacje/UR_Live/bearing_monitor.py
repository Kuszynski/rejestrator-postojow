# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  SYSTEM DIAGNOSTYKI ÅOÅ»YSK â€” LINIA TARTAKU                                â•‘
â•‘  Condition Monitoring Engine v1.0                                          â•‘
â•‘                                                                            â•‘
â•‘  Metodyka:                                                                 â•‘
â•‘    1. SKF â€” Crest Factor (wspÃ³Å‚czynnik szczytu wibracji)                   â•‘
â•‘    2. Siemens â€” Baseline Deviation (adaptacyjna linia bazowa 7-dniowa)     â•‘
â•‘    3. AWS Amazon Monitron â€” Anomaly Gradient (gradient temperatury)         â•‘
â•‘                                                                            â•‘
â•‘  Cel: OdrÃ³Å¼niÄ‡ "stary wiek maszyny" od "nadchodzÄ…cej katastrofy"          â•‘
â•‘  Dane wejÅ›ciowe: CSV z czujnikÃ³w IoT (timestamp, unit, value)             â•‘
â•‘  Autor: IIoT Condition Monitoring Engineer                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Uzasadnienie biznesowe:
    Standardowe alarmy statystyczne (prÃ³g 70Â°C, wibracje > 4g) nie dziaÅ‚ajÄ…
    w starych maszynach tartaku, poniewaÅ¼ ich "normalny" poziom szumu jest
    wyÅ¼szy niÅ¼ normy ISO 10816 dla nowych maszyn. Ten system stosuje
    podejÅ›cie relatywne â€” porÃ³wnuje maszynÄ™ do niej samej, nie do ksiÄ…Å¼kowych
    norm.

Referencje standardÃ³w:
    - SKF Application Note: "Vibration Diagnostic Guide" (wspÃ³Å‚czynnik szczytu)
    - ISO 10816-3:2009 â€” Wibracje maszyn (kontekst, nie progi)
    - Siemens SITRANS MS200 / MindSphere â€” Predictive Analytics (adaptive baseline)
    - AWS Amazon Monitron â€” Machine Learning anomaly detection (gradient-based)
    - ISO 13373-1:2002 â€” Condition monitoring and diagnostics of machines
"""

import pandas as pd
import numpy as np
from datetime import timedelta, time
import warnings
import os
import sys
import io

# WymuÅ› UTF-8 dla konsoli Windows
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except (AttributeError, io.UnsupportedOperation):
        pass

warnings.filterwarnings('ignore')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  KONFIGURACJA â€” PROGI ALARMOWE
#  Dostosuj do specyfiki swojej linii produkcyjnej.
#  KaÅ¼dy prÃ³g jest udokumentowany odniesieniem do standardu branÅ¼owego.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# --- SKF: Crest Factor (WspÃ³Å‚czynnik Szczytu) ---
# Ref: SKF Application Note â€” "Bearing damage and failure analysis"
# CF = Peak / RMS. Nowe Å‚oÅ¼ysko: CF â‰ˆ 3. Uszkodzenie bieÅ¼ni: CF > 5-6.
# Gdy CF roÅ›nie powyÅ¼ej 5, oznacza to impulsy mechaniczne (pÄ™kniÄ™cia kulek,
# odpryski bieÅ¼ni) â€” zanim jeszcze wzroÅ›nie temperatura.
SKF_CF_NORMAL = 3.0       # CF < 3.0 â†’ Å‚oÅ¼ysko zdrowe
SKF_CF_WARNING = 5.0      # 3.0 â‰¤ CF < 5.0 â†’ wczesne mikro-pittingi
SKF_CF_CRITICAL = 6.0     # CF â‰¥ 6.0 â†’ powaÅ¼ne uszkodzenie fizyczne
SKF_VIBRATION_IDLE = 0.1  # g â€” Idle bypass (ignoruje wibracje tÅ‚a poniÅ¼ej 0.1g)

# --- Siemens: Baseline Deviation (Adaptacyjna Banda Statystyczna) ---
# Ref: Siemens MindSphere / AWS Monitron â€” adaptive statistical bands
# Zamiast sztywnego "25% odchylenia" (ktÃ³ry nie uwzglÄ™dnia naturalnej
# zmiennoÅ›ci maszyny), stosujemy bandÄ™ Î¼ Â± NÃ—Ïƒ.
# JeÅ›li maszyna normalnie waha siÄ™ Â±15%, banda bÄ™dzie szersza.
# JeÅ›li maszyna jest stabilna (Â±3%), banda bÄ™dzie ciaÅ›niejsza.
SIEMENS_BASELINE_WINDOW = '30D'  # Okno bazowe: 30 dni (~20 cykli produkcyjnych)
                                  # 7 dni to za maÅ‚o dla maszyn start-stop (tylko ~5 cykli)
SIEMENS_SIGMA_WARNING = 2.0      # Î¼ Â± 2Ïƒ â†’ PLANLEGG SERVICE (ğŸŸ¡) (95.4% pewnoÅ›ci anomalii)
SIEMENS_SIGMA_CRITICAL = 3.0     # Î¼ Â± 3Ïƒ â†’ KRITISK ALARM (ğŸ”´) (99.7% pewnoÅ›ci anomalii)
SIEMENS_STEADYSTATE_WINDOW = 6   # InterwaÅ‚y (30 min) do oceny stabilnoÅ›ci maszyny
SIEMENS_STEADYSTATE_CV_MAX = 0.15  # Max wspÃ³Å‚czynnik zmiennoÅ›ci (15%) = steady state

# --- AWS Monitron: Anomaly Gradient (Gradient Temperatury) ---
# Ref: AWS Monitron â€” "Abnormal condition detection using rate of change"
# KALIBRACJA na podstawie rzeczywistego poÅ¼aru 13.02.2026:
#   - Prawdziwy poÅ¼ar: gradient +23Â°C/h â†’ +57Â°C/h (o 07:15-07:20)
#   - Normalna praca: 99.9 percentyl = +14.4Â°C/h
#   - PRÃ“G MIÄ˜DZY NIMI: 15Â°C/h
# UWAGA: Tylko DODATNIE gradienty (grzanie) sÄ… niebezpieczne.
# Ujemny gradient = chÅ‚odzenie = BEZPIECZNE.
AWS_GRADIENT_WINDOW = '1h'       # Okno obliczeÅ„ gradientu
AWS_GRADIENT_WARNING = 10.0      # Â°C/h â†’ Warning
AWS_GRADIENT_CRITICAL = 15.0     # Â°C/h â†’ Critical / Fire (ğŸ”´ğŸ”¥)
AWS_GRADIENT_FIRE_EXTREME = 30.0 # Â°C/h â†’ Extreme Fire (natychmiastowy stop linii)
AWS_MIN_FIRE_TEMP = 45.0         # Â°C â†’ Minimalna temp wymagana dla poÅ¼aru
# --- NOWY: PodÅ‚oga wibracji dla alarmÃ³w krytycznych ---
# Chroni przed nadawaniem statusu BRANN na bardzo cichych maszynach (np. 0.3g)
# ktÃ³re statystycznie majÄ… anomaliÄ™, ale fizycznie nic im nie grozi.
SIEMENS_MIN_CRITICAL_RMS = 0.3   # g 

# DzieÅ„ produkcyjny: 06:00 â€” 23:20
# Przerwy: 09:30â€“10:00 (Å›niadanie), 19:00â€“19:30 (kolacja)
# Poza tymi godzinami maszyna jest wyÅ‚Ä…czona â€” ignoruj szum czujnikÃ³w.
# Gradienty na granicach start/stop/przerwa sÄ… naturalne i NIE powinny
# wywoÅ‚ywaÄ‡ alarmÃ³w (nagrzewanie zimnego Å‚oÅ¼yska â‰  awaria).
PRODUCTION_START = time(6, 0)     # Start zmiany: 06:00
PRODUCTION_END = time(23, 20)     # Koniec zmiany: 23:20
BREAKS = [
    (time(9, 30), time(10, 0)),   # Przerwa Å›niadaniowa
    (time(19, 0), time(19, 30)),  # Przerwa kolacyjna
]
# Ile minut po starcie/przerwie ignorowaÄ‡ gradient (czas nagrzewania)
WARMUP_MINUTES = 60

# --- Alarm Persistence (TrwaÅ‚oÅ›Ä‡ Alarmu) ---
# Ref: SKF Enlight / IMx â€” alarm debounce
# Pojedynczy spike wibracji (np. wÃ³zek widÅ‚owy, uderzenie kÅ‚ody) nie powinien
# wywoÅ‚ywaÄ‡ alarmu. Prawdziwa degradacja Å‚oÅ¼yska trwa â€” jest widoczna
# w KOLEJNYCH prÃ³bkach. Wymagamy N kolejnych interwaÅ‚Ã³w powyÅ¼ej progu.
ALARM_PERSISTENCE_INTERVALS = 2  # 2 Ã— 5min = 10 minut ciÄ…gÅ‚ego alarmu (zmniejszono z 15 min dla ekstremalnej czuÅ‚oÅ›ci)
ALARM_PERSISTENCE_FIRE = 1       # 1 Ã— 5min = NATYCHMIAST dla POÅ»AR/STOP (W uÅ‚amku sekund temperatura nie robi false spikes, tylko pÅ‚onie!)
# PoÅ¼ar (Gradient > 15C/h) nie podlega zwÅ‚oce! BezwÅ‚adnoÅ›Ä‡ cieplna litego Å¼eliwa 
# uniemoÅ¼liwia bÅ‚Ä™dy pomiarowe np. o 20 stopni / h z powietrza. 
# Czekanie 15 minut przy poÅ¼arze to pewne spalenie linii.

# --- Random Cut Forest (4. silnik: AWS Monitron ML) ---
# Ref: AWS Monitron â€” "Robust Random Cut Forest Based Anomaly Detection"
# Ref: Guha et al., 2016 â€” "Robust Random Cut Forest" (ICML)
# RCF analizuje WIELE wymiarÃ³w jednoczeÅ›nie (temperatura, wibracje, CF, gradient)
# i szuka punktÃ³w, ktÃ³re sÄ… "Å‚atwe do oddzielenia" od reszty danych.
# To samo co AWS Monitron robi wewnÄ™trznie na czujnikach.
RCF_NUM_TREES = 100              # IloÅ›Ä‡ drzew w lesie (wiÄ™cej = stabilniejsze wyniki)
RCF_TREE_SIZE = 256              # Max punktÃ³w na drzewo (okno uczenia)
RCF_FEATURES = [                 # Cechy wejÅ›ciowe â€” wielowymiarowa analiza
    'vib_rms',                   #   Energia wibracji
    'temp_mean',                 #   Temperatura Å‚oÅ¼yska
    'crest_factor',              #   ImpulsowoÅ›Ä‡ sygnaÅ‚u (SKF)
    'temp_gradient_final',       #   SzybkoÅ›Ä‡ zmian temperatury (AWS)
    'avg_line_vibration'         #   Korelacja Sagi â€” Å›rednia wibracja na Linii
]
# --- ISO 10816-1: Vibration Severity (Absolute Norms) ---
# Klasa I: MaÅ‚e maszyny (do 15 kW) â€” standard dla przenoÅ›nikÃ³w
ISO_VIB_ZONE_A_B = 0.71  # mm/s (Granica miÄ™dzy Dobrym a ZadowalajÄ…cym)
ISO_VIB_ZONE_B_C = 1.80  # mm/s (Granica miÄ™dzy ZadowalajÄ…cym a NiepokojÄ…cym)
ISO_VIB_ZONE_C_D = 4.50  # mm/s (Granica miÄ™dzy NiepokojÄ…cym a Niedopuszczalnym)

# Progi anomalii RCF (Random Cut Forest) kalibrowane automatycznie z danych:
RCF_PERCENTILE_WARNING = 99.0    # Score > 99.0-ty percentyl â†’ PLANLEGG SERVICE
RCF_PERCENTILE_CRITICAL = 99.9   # Score > 99.9-ty percentyl â†’ KRITISK ALARM

# --- Agregacja ---
AGGREGATION_INTERVAL = '5min'    # InterwaÅ‚ prÃ³bkowania: 5 minut


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 1: ÅADOWANIE I PRZYGOTOWANIE DANYCH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_sensor_data(filepath: str) -> pd.DataFrame:
    """
    Wczytaj dane z CSV eksportowanego z systemu IoT.
    Format: sn;time;unit;value;timestamp
    Separator: ; (standard europejski)
    """
    print(f"  [LOAD] {os.path.basename(filepath)}")
    df = pd.read_csv(
        filepath,
        sep=';',
        dtype={'sn': str, 'unit': str, 'value': float}
    )
    df['timestamp'] = pd.to_datetime(df['timestamp'], format='ISO8601')
    
    # Skrypt pobieraÅ‚ czas UTC z CSV i gubiÅ‚ polskÄ… strefÄ™ (zima +1, lato +2)
    # Ratuje to przeliczenie na Europe/Warsaw i zrzucenie obrysu z UTC by pÄ™tle czasu 06:00 itp dziaÅ‚aÅ‚y precyzyjnie.
    if df['timestamp'].dt.tz is not None:
        df['timestamp'] = df['timestamp'].dt.tz_convert('Europe/Warsaw').dt.tz_localize(None)

    df = df.sort_values('timestamp').reset_index(drop=True)
    print(f"     â†’ {len(df):,} rekordÃ³w, zakres (PL): {df['timestamp'].min()} â€” {df['timestamp'].max()}")
    return df


def prepare_bearing_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Rozdziel dane Å‚oÅ¼yskowe na kanaÅ‚y wibracji (g) i temperatury (Â°C).
    Agreguj do interwaÅ‚Ã³w 5-minutowych.

    Agregacja wibracji:
      - max: wartoÅ›Ä‡ szczytowa (peak) â€” potrzebna do Crest Factor (SKF)
      - mean: Å›rednia â€” potrzebna do baseline (Siemens)
      - rms: âˆš(mean(xÂ²)) â€” standard ISO 10816 dla oceny wibracji
      - std: odchylenie standardowe â€” informacja dodatkowa

    Agregacja temperatury:
      - mean: Å›rednia w oknie â€” wystarczajÄ…ca dla gradientu (AWS Monitron)
    """
    # Rozdziel kanaÅ‚y
    if 'vib_rms' in df.columns and 'temp_mean' in df.columns:
        # Format "wide" (nowy daemon) - przygotuj do agregacji
        vib = df[['timestamp', 'vib_rms']].copy().rename(columns={'vib_rms': 'value'})
        vib['unit'] = 'g'
        temp = df[['timestamp', 'temp_mean']].copy().rename(columns={'temp_mean': 'value'})
        temp['unit'] = 'Â°C'
    else:
        # Format "long" (klasyczny CSV)
        vib = df[df['unit'] == 'g'].copy()
        temp = df[df['unit'] == 'Â°C'].copy()

    vib = vib.set_index('timestamp')
    temp = temp.set_index('timestamp')

    # Agregacja wibracji co 5 minut
    # RMS obliczamy rÄ™cznie: âˆš(mean(xÂ²))
    vib_agg = vib['value'].resample(AGGREGATION_INTERVAL).agg(
        vib_max='max',
        vib_mean='mean',
        vib_std='std',
        vib_count='count'
    )

    # RMS = âˆš(mean(xÂ²)) â€” standard ISO 10816 dla oceny energii wibracji
    vib_rms = vib['value'].resample(AGGREGATION_INTERVAL).apply(
        lambda x: np.sqrt(np.mean(x**2)) if len(x) > 0 else 0
    ).rename('vib_rms')

    # Agregacja temperatury co 5 minut
    temp_agg = temp['value'].resample(AGGREGATION_INTERVAL).agg(
        temp_mean='mean',
        temp_max='max',
        temp_min='min'
    )

    # PoÅ‚Ä…cz w jednÄ… ramkÄ™
    result = pd.concat([vib_agg, vib_rms, temp_agg], axis=1)

    # UzupeÅ‚nij brakujÄ…ce interwaÅ‚y (forward fill z limitem 3 prÃ³bek = 15min)
    result = result.ffill(limit=3)
    
    # [POPRAWKA] Nie wyrzucaj rekordÃ³w, ktÃ³re majÄ… tylko temperaturÄ™ (np. czujnik hali)
    # Wyrzucamy tylko jeÅ›li NIE MA ANI temperatury ANI wibracji
    result = result.dropna(how='all', subset=['vib_rms', 'temp_mean'])
    
    # Zapewnij 0.0 zamiast NaN dla wibracji jeÅ›li ich brak (bezpieczne dla dashboardu)
    if 'vib_rms' in result.columns:
        result['vib_rms'] = result['vib_rms'].fillna(0.0)
    if 'vib_max' in result.columns:
        result['vib_max'] = result['vib_max'].fillna(0.0)

    print(f"     â†’ Zagregowano do {len(result)} interwaÅ‚Ã³w 5-min")

    # Oznacz harmonogram produkcji
    result = classify_production_time(result)
    prod_count = result['is_production'].sum()
    break_count = result['is_break'].sum()
    idle_count = len(result) - prod_count - break_count
    print(f"     â†’ Produkcja: {prod_count} | Przerwy: {break_count} | Poza zmianÄ…: {idle_count}")

    return result


def classify_production_time(df: pd.DataFrame) -> pd.DataFrame:
    """
    Oznacz kaÅ¼dy interwaÅ‚ jako: produkcja, przerwa, lub poza zmianÄ… ZALEÅ»NIE OD DANYCH RZECZYWISTYCH.
    Saga i rÄ™baki to ukÅ‚ady dynamiczne, czÄ™sto stajÄ… poza harmonogramem.
    
    Nowa logika behawioralna:
      - Silnik pracuje (is_production = True), jeÅ¼eli vib_rms > bieg jaÅ‚owy.
      - Przerwa (is_break = True), jeÅ¼eli silnik fizycznie stoi.
      - Warmup odpalany na starcie danego silnika.
    """
    df = df.copy()

    # Silnik pracuje, jeÅ›li wibracje przekraczajÄ… prÃ³g szumu jaÅ‚owego
    df['is_production'] = df['vib_rms'] > SKF_VIBRATION_IDLE

    # Przerwa to czas, gdy maszyna (silnik) nie pracuje
    df['is_break'] = ~df['is_production']

    # Wykrywanie "warmupu" (rozgrzewki)
    # Znajdujemy momenty startu (przejÅ›cie z false do true dla is_production)
    starts = df['is_production'] & ~df['is_production'].shift(1, fill_value=False)

    interval_minutes = int(pd.Timedelta(AGGREGATION_INTERVAL).total_seconds() / 60)
    warmup_intervals = WARMUP_MINUTES // interval_minutes
    
    # Tworzymy maskÄ™ rozgrzewki: przedÅ‚uÅ¼amy flagÄ™ startu na przÃ³d o 'warmup_intervals' interwaÅ‚Ã³w
    df['is_warmup'] = starts.replace(False, np.nan).ffill(limit=warmup_intervals).fillna(False).astype(bool)
    
    # CiepÅ‚o ma znaczenie tylko wtedy, gdy maszyna rzeczywiÅ›cie pracuje
    df['is_warmup'] = df['is_warmup'] & df['is_production']

    return df


def prepare_hall_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Przygotuj dane temperatury hali jako referencjÄ™ otoczenia.
    UÅ¼ywane do kompensacji: Î”T_skorygowane = T_Å‚oÅ¼ysko - T_hala
    """
    if 'temp_mean' in df.columns:
        # Format wide
        temp = df[['timestamp', 'temp_mean']].copy().rename(columns={'temp_mean': 'value'})
    else:
        # Format long
        temp = df[df['unit'] == 'Â°C'].copy()

    temp = temp.set_index('timestamp')

    hall_agg = temp['value'].resample(AGGREGATION_INTERVAL).agg(
        hall_temp='mean'
    )
    hall_agg = hall_agg.ffill(limit=6)  # Czujnik halowy ma rzadsze odczyty

    print(f"     â†’ Temperatura hali: {len(hall_agg)} interwaÅ‚Ã³w")
    return hall_agg


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 2: LOGIKA SKF â€” CREST FACTOR (WspÃ³Å‚czynnik Szczytu)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_skf_crest_factor(df: pd.DataFrame) -> pd.DataFrame:
    """
    SKF Crest Factor Analysis â€” wykrywanie uszkodzeÅ„ mechanicznych Å‚oÅ¼ysk.

    Teoria (SKF Application Note):
        Crest Factor = Peak / RMS
        - Nowe Å‚oÅ¼ysko: CF â‰ˆ 2-3 (sygnaÅ‚ sinusoidalny)
        - Wczesne uszkodzenie bieÅ¼ni: CF = 3-5 (pojawiajÄ… siÄ™ impulsy)
        - Zaawansowane uszkodzenie: CF > 5-6 (silne impulsy, odpryski)
        - Katastrofalne uszkodzenie: CF spada (szum maskuje impulsy)

    UWAGA: CF jest czuÅ‚y na WCZESNE uszkodzenia â€” wykrywa pÄ™kniÄ™cia
    ZANIM temperatura zacznie rosnÄ…Ä‡. To daje czas na planowany serwis.

    Dla maszyny wyÅ‚Ä…czonej (wibracje < 0.01g) CF = 0 (brak danych).
    """
    df = df.copy()

    # Oblicz Crest Factor tylko gdy maszyna pracuje W CZASIE PRODUKCJI
    # Unikamy dzielenia przez zero i szumu z wyÅ‚Ä…czonej maszyny
    mask_running = (df['vib_rms'] > SKF_VIBRATION_IDLE) & df['is_production']
    df['crest_factor'] = 0.0
    df.loc[mask_running, 'crest_factor'] = (
        df.loc[mask_running, 'vib_max'] / df.loc[mask_running, 'vib_rms']
    )

    # Klasyfikacja SKF
    conditions = [
        ~df['is_production'] | df['is_break'],           # Poza zmianÄ… / Przerwa
        df['is_warmup'],                                 # Rozgrzewka (maskujemy skoki)
        df['crest_factor'] < SKF_CF_NORMAL,             # Zdrowe Å‚oÅ¼ysko
        (df['crest_factor'] >= SKF_CF_NORMAL) &
            (df['crest_factor'] < SKF_CF_WARNING),      # Wczesne zuÅ¼ycie
        (df['crest_factor'] >= SKF_CF_WARNING) &
            (df['crest_factor'] < SKF_CF_CRITICAL),     # PostÄ™pujÄ…ce zuÅ¼ycie
        df['crest_factor'] >= SKF_CF_CRITICAL            # Uszkodzenie krytyczne
    ]
    choices = [
        'IDLE',
        'ğŸŸ¢ MONITORING',
        'ğŸŸ¢ MONITORING',
        'ğŸŸ¡ PLANLEGG SERVICE',
        'ğŸŸ¡ PLANLEGG SERVICE',
        'ğŸ”´ KRITISK ALARM'
    ]
    df['skf_status'] = np.select(conditions, choices, default='UNKNOWN')

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 3: LOGIKA SIEMENS â€” BASELINE DEVIATION (Adaptacyjna Linia Bazowa)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_siemens_baseline(df: pd.DataFrame) -> pd.DataFrame:
    """
    Siemens Adaptive Baseline â€” banda statystyczna Î¼ Â± NÃ—Ïƒ.

    Teoria (Siemens MindSphere / AWS Monitron Adaptive Bands):
        Zamiast sztywnego progu "25% odchylenia", obliczamy:

        Î¼ = Å›rednia kroczÄ…ca RMS z 7 dni produkcji
        Ïƒ = odchylenie standardowe RMS z tego samego okna

        Alarm WARNING:  RMS > Î¼ + 2Ïƒ  lub  RMS < Î¼ - 2Ïƒ  (95.4%)
        Alarm CRITICAL: RMS > Î¼ + 3Ïƒ  lub  RMS < Î¼ - 3Ïƒ  (99.7%)

    Dlaczego to lepsze niÅ¼ sztywne 25%:
        - Maszyna z naturalnÄ… zmiennoÅ›ciÄ… Â±20% â†’ banda szeroka â†’ mniej faÅ‚szywych
        - Maszyna stabilna (Â±3%) â†’ banda ciasna â†’ szybsze wykrycie anomalii
        - System AUTOMATYCZNIE dostosowuje siÄ™ do charakterystyki maszyny

    Steady-State Filter (filtr stanu ustalonego):
        Alarmy nadajemy TYLKO gdy maszyna jest w stanie ustalonym.
        Startup, rampa, zmiana obciÄ…Å¼enia â†’ ignorujemy.
        Stan ustalony = wspÃ³Å‚czynnik zmiennoÅ›ci (CV) w oknie 30min < 15%.

    Parametr okna (7 dni) wybrany celowo:
        - 7 dni = kompromis rekomendowany przez Siemens dla maszyn ciÄ…gÅ‚ych
    """
    df = df.copy()

    # â”€â”€ Baseline obliczamy TYLKO na danych produkcyjnych â”€â”€
    production_rms = df['vib_rms'].copy()
    production_rms[~df['is_production']] = np.nan

    # Î¼ (Å›rednia) i Ïƒ (odchylenie standardowe) z okna 7 dni
    df['baseline_7d'] = production_rms.rolling(
        window=SIEMENS_BASELINE_WINDOW,
        min_periods=1
    ).mean()

    df['baseline_7d_std'] = production_rms.rolling(
        window=SIEMENS_BASELINE_WINDOW,
        min_periods=1
    ).std()

    # Bandy statystyczne: Î¼ Â± 2Ïƒ (warning) i Î¼ Â± 3Ïƒ (critical)
    df['band_warning_upper'] = df['baseline_7d'] + SIEMENS_SIGMA_WARNING * df['baseline_7d_std']
    df['band_warning_lower'] = df['baseline_7d'] - SIEMENS_SIGMA_WARNING * df['baseline_7d_std']
    df['band_critical_upper'] = df['baseline_7d'] + SIEMENS_SIGMA_CRITICAL * df['baseline_7d_std']
    df['band_critical_lower'] = df['baseline_7d'] - SIEMENS_SIGMA_CRITICAL * df['baseline_7d_std']

    # â”€â”€ Steady-State Detection (Siemens approach) â”€â”€
    # CV = Ïƒ_local / Î¼_local â€” jeÅ›li CV < 15%, maszyna jest stabilna
    local_mean = production_rms.rolling(
        window=SIEMENS_STEADYSTATE_WINDOW, min_periods=3
    ).mean()
    local_std = production_rms.rolling(
        window=SIEMENS_STEADYSTATE_WINDOW, min_periods=3
    ).std()
    df['is_steady_state'] = (
        (local_std / local_mean.replace(0, np.nan)).fillna(1.0)
        < SIEMENS_STEADYSTATE_CV_MAX
    ) & df['is_production']

    # Oblicz odchylenie procentowe (zachowujemy dla raportu / CSV)
    df['baseline_deviation_pct'] = 0.0
    mask_active = (df['baseline_7d'] > SKF_VIBRATION_IDLE) & df['is_production']
    df.loc[mask_active, 'baseline_deviation_pct'] = (
        (df.loc[mask_active, 'vib_rms'] - df.loc[mask_active, 'baseline_7d'])
        / df.loc[mask_active, 'baseline_7d'] * 100
    )

    # â”€â”€ Klasyfikacja Siemens â€” banda statystyczna + steady-state â”€â”€
    mask_steady_active = mask_active & df['is_steady_state']

    conditions = [
        ~df['is_production'],                                           # Poza zmianÄ…
        ~mask_active,                                                   # Maszyna wyÅ‚Ä…czona
        df['is_warmup'],                                                # Rozgrzewka maszyny
        ~df['is_steady_state'] & df['is_production'],                  # Stan przejÅ›ciowy â†’ OK
        # Steady-state: porÃ³wnaj do band
        mask_steady_active & ~df['is_warmup'] &
            (df['vib_rms'] >= df['band_warning_lower']) &
            (df['vib_rms'] <= df['band_warning_upper']),                # W bandzie â†’ OK
        mask_steady_active & ~df['is_warmup'] &
            ((df['vib_rms'] > df['band_warning_upper']) |
             (df['vib_rms'] < df['band_warning_lower'])) &
            (df['vib_rms'] <= df['band_critical_upper']) &
            (df['vib_rms'] >= df['band_critical_lower']),              # Poza 2Ïƒ
        mask_steady_active & ~df['is_warmup'] &
            ((df['vib_rms'] > df['band_critical_upper']) |
             (df['vib_rms'] < df['band_critical_lower']))              # Poza 3Ïƒ
    ]
    choices = [
        'IDLE',
        'IDLE',
        'ğŸŸ¢ MONITORING',          # Rozgrzewka
        'ğŸŸ¢ MONITORING',          # Stan przejÅ›ciowy â€” nie alarmuj
        'ğŸŸ¢ MONITORING',          # WewnÄ…trz bandy 2Ïƒ
        'ğŸŸ¡ PLANLEGG SERVICE',    # Poza bandÄ… 2Ïƒ â€” trend
        'ğŸ”´ KRITISK ALARM'        # Poza bandÄ… 3Ïƒ â€” anomalia
    ]
    df['siemens_status'] = np.select(conditions, choices, default='UNKNOWN')

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 4: LOGIKA AWS MONITRON â€” ANOMALY GRADIENT (Gradient Temperatury)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_aws_gradient(df: pd.DataFrame, hall_temp: pd.Series = None) -> pd.DataFrame:
    """
    AWS Monitron Gradient Analysis â€” alarmowanie oparte na szybkoÅ›ci zmian.

    Teoria (AWS Monitron Anomaly Detection):
        Nie pytaj "czy temperatura > 100Â°C?" â€” pytaj "jak SZYBKO roÅ›nie?"

        Gradient = Î”T / Î”t (Â°C na godzinÄ™)

        ÅoÅ¼ysko, ktÃ³re nagrzaÅ‚o siÄ™ z 40Â°C do 55Â°C w ciÄ…gu godziny (+15Â°C/h)
        jest BARDZIEJ niebezpieczne niÅ¼ Å‚oÅ¼ysko stojÄ…ce stabilnie na 80Â°C.

        Dlaczego? Bo gradient 15Â°C/h oznacza:
        - Utrata smarowania (olej wyciekÅ‚ lub siÄ™ rozÅ‚oÅ¼yÅ‚)
        - Zacieranie bieÅ¼ni
        - PoÅ¼ar za 2-3 godziny

    Kompensacja temperatury otoczenia:
        JeÅ›li dostÄ™pne sÄ… dane z czujnika halowego, gradient jest obliczany
        na podstawie rÃ³Å¼nicy (T_Å‚oÅ¼ysko - T_hala), eliminujÄ…c wpÅ‚yw
        pogody i ogrzewania hali na alarmy.

    KLUCZOWE: Ten alarm dziaÅ‚a NIEZALEÅ»NIE od wartoÅ›ci bezwzglÄ™dnej temperatury.
    Gradient 8Â°C/h przy 30Â°C jest TAK SAMO groÅºny jak przy 60Â°C.
    """
    df = df.copy()

    # Zabezpieczenie przed brakiem temperatury
    if 'temp_mean' not in df.columns:
        # print(f"  [AWS WARN] Brak 'temp_mean', omijam kalkulacje gradientu.")
        df['temp_compensated'] = 0.0
        df['temp_gradient'] = 0.0
        df['temp_gradient_smooth'] = 0.0
        df['temp_gradient_final'] = 0.0
        df['p_aws'] = 0
        df['aws_status'] = 'ğŸŸ¢ MONITORING (No Temp Data)'
        return df

    # JeÅ›li mamy dane halowe, uÅ¼yj rÃ³Å¼nicy temperatur (kompensacja otoczenia)
    if hall_temp is not None and 'temp_mean' in df.columns:
        # DoÅ‚Ä…cz temperaturÄ™ hali (nearest match w indeksie czasowym)
        df = df.join(hall_temp, how='left')
        df['hall_temp'] = df['hall_temp'].ffill().bfill()
        df['temp_compensated'] = df['temp_mean'] - df['hall_temp']
        temp_col = 'temp_compensated'
        print("     â†’ Kompensacja temperatury otoczenia: AKTYWNA (czujnik halowy)")
    else:
        temp_col = 'temp_mean'
        print("     â†’ Kompensacja temperatury otoczenia: BRAK (brak danych halowych)")

    # Oblicz gradient temperatury (Â°C/h) z oknem 1h
    # UÅ¼ywamy diff() / diff(periods) = zmiana w oknach 5-min, skalowana do Â°C/h
    # 1 godzina = 12 interwaÅ‚Ã³w 5-minutowych
    periods_per_hour = int(pd.Timedelta('1h') / pd.Timedelta(AGGREGATION_INTERVAL))

    df['temp_gradient'] = (
        df[temp_col].diff(periods=periods_per_hour)
        / (periods_per_hour * 5 / 60)  # Normalizacja do Â°C/h
    )

    # Alternatywnie: gradient kroczÄ…cy z okna 1h (bardziej wygÅ‚adzony)
    df['temp_gradient_smooth'] = df[temp_col].rolling(
        window=periods_per_hour, min_periods=2
    ).apply(
        lambda x: (x.iloc[-1] - x.iloc[0]) / (len(x) * 5 / 60) if len(x) > 1 else 0,
        raw=False
    )

    # UÅ¼yj wygÅ‚adzonego gradientu jako gÅ‚Ã³wnego
    df['temp_gradient_final'] = df['temp_gradient_smooth'].fillna(df['temp_gradient']).fillna(0)

    # â”€â”€ TYLKO DODATNIE gradienty sÄ… niebezpieczne â”€â”€
    # Ujemny gradient = Å‚oÅ¼ysko siÄ™ chÅ‚odzi = DOBRZE.
    # Kalibracja na podstawie prawdziwego poÅ¼aru 13.02.2026:
    #   - Normalny gradient produkcyjny: 95th percentyl = +9.9Â°C/h
    #   - Prawdziwy poÅ¼ar: +23Â°C/h â†’ +57Â°C/h
    #   - PrÃ³g CRITICAL: 15Â°C/h (miÄ™dzy 99.9th a poÅ¼arem)
    gradient_for_alarm = df['temp_gradient_final'].copy()
    
    # Ekstremalny poÅ¼ar traktujemy ostro przy poÅ¼arze (ponad temp min)
    is_extreme = (df['temp_gradient_final'] >= AWS_GRADIENT_FIRE_EXTREME) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP)
    
    gradient_for_alarm[~df['is_production'] & ~is_extreme] = 0.0    # Poza zmianÄ… â€” ignoruj
    gradient_for_alarm[df['is_warmup'] & ~is_extreme] = 0.0         # Rozgrzewka â€” ignoruj
    gradient_for_alarm[df['is_break'] & ~is_extreme] = 0.0          # Przerwa â€” ignoruj
    # Zabezpieczenie przed "Cold Startem" - poÅ¼ar zawsze powoduje wyÅ¼szÄ… temperaturÄ™.
    
    conditions = [
        (gradient_for_alarm >= AWS_GRADIENT_FIRE_EXTREME) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP), # ğŸ”¥ EKSTREMALNY POÅ»AR
        ~df['is_production'] | df['is_break'],                       # Poza zmianÄ…
        gradient_for_alarm < AWS_GRADIENT_WARNING,                   # Stabilna
        (gradient_for_alarm >= AWS_GRADIENT_WARNING) &
        (gradient_for_alarm < AWS_GRADIENT_CRITICAL),                # Trend grzania
        (gradient_for_alarm >= AWS_GRADIENT_CRITICAL) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP),     # Prawdziwy Krytyczny
        gradient_for_alarm >= AWS_GRADIENT_CRITICAL                  # Alarm zdegradowany przez niskÄ… temperaturÄ™ fizycznÄ… (zimny start)
    ]
    choices = [
        'ğŸ”´ğŸ”¥ BRANN/STOPP',
        'IDLE',
        'ğŸŸ¢ MONITORING',
        'ğŸŸ¡ PLANLEGG SERVICE',
        'ğŸ”´ğŸ”¥ BRANN/STOPP',
        'ğŸŸ¡ PLANLEGG SERVICE'                                           # Zimny rozbieg zdegradowany do statusu Å¼Ã³Å‚tego!
    ]
    df['aws_status'] = np.select(conditions, choices, default='UNKNOWN')

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 4B: RANDOM CUT FOREST â€” AWS MONITRON ML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_rcf_anomaly(df: pd.DataFrame) -> pd.DataFrame:
    """
    Isolation Forest â€” wielowymiarowa detekcja anomalii (rodzina RCF).

    Teoria (Liu et al., 2008 / AWS Monitron):
        Isolation Forest i Random Cut Forest naleÅ¼Ä… do tej samej rodziny
        algorytmÃ³w: tree-based isolation anomaly detection.

        AWS Monitron uÅ¼ywa RCF (Guha et al., 2016) â€” streamingowa wersja.
        sklearn IsolationForest to batch-wersja z C-optymalizacjÄ…,
        idealna do analizy historycznych danych CSV.

        Zasada dziaÅ‚ania (obie wersje):
        1. Buduj losowe drzewa na wielowymiarowych danych
        2. Anomalie = punkty "Å‚atwe do oddzielenia" (krÃ³tka Å›cieÅ¼ka w drzewie)
        3. Normalne punkty = gÅ‚Ä™boko w drzewie (trudne do oddzielenia)

    Cechy wejÅ›ciowe (4D):
        - vib_rms:              Energia wibracji
        - temp_mean:            Temperatura Å‚oÅ¼yska
        - crest_factor:         ImpulsowoÅ›Ä‡ (uszkodzenia mechaniczne)
        - temp_gradient_final:  SzybkoÅ›Ä‡ zmian temperatury

    Trenowanie:
        Tylko na danych PRODUKCYJNYCH.
        Standaryzacja z-score na kaÅ¼dej cesze.

    Klasyfikacja:
        Score < P1 (1-ty percentyl) â†’ ANOMALIA KRYTYCZNA (najbardziej izolowane)
        Score < P5 (5-ty percentyl) â†’ ANOMALIA WARNING
        Reszta â†’ MONITORING

    Uwaga: IsolationForest zwraca ujemne score dla anomalii
    (im bardziej ujemny, tym bardziej anomalny).
    """
    from sklearn.ensemble import IsolationForest
    from sklearn.preprocessing import StandardScaler

    df = df.copy()
    df['rcf_score'] = 0.0
    df['rcf_status'] = 'IDLE'

    # Zabezpieczenie przed brakiem temp_mean i temp_gradient_final
    for col in ['temp_mean', 'temp_gradient_final']:
        if col not in df.columns:
            df[col] = 0.0

    # Filtruj: trenujemy TYLKO na produkcji
    prod_mask = df['is_production'] & ~df['is_break']
    prod_df = df[prod_mask].copy()

    if len(prod_df) < 500:
        print("     âš ï¸  Za maÅ‚o danych produkcyjnych dla RCF")
        return df

    # Przygotuj cechy â€” uÅ¼ywamy tylko tych dostÄ™pnych w DF
    actual_features = [f for f in RCF_FEATURES if f in prod_df.columns]
    if not actual_features:
        return df
        
    features = prod_df[actual_features].fillna(0).values
    scaler = StandardScaler()
    features_norm = scaler.fit_transform(features)

    # Buduj Isolation Forest (C-optymalizowany, sekundy zamiast minut)
    print(f"     â†’ Budowanie lasu: {RCF_NUM_TREES} drzew Ã— {RCF_TREE_SIZE} prÃ³bek...")
    model = IsolationForest(
        n_estimators=RCF_NUM_TREES,
        max_samples=min(RCF_TREE_SIZE, len(features_norm)),
        contamination='auto',  # Automatyczna kalibracja
        random_state=42,
        n_jobs=-1              # UÅ¼yj wszystkich rdzeni CPU
    )
    model.fit(features_norm)

    # Score: im bardziej ujemny, tym bardziej anomalny
    scores = model.decision_function(features_norm)

    # Oblicz progi na podstawie rozkÅ‚adu (dolne percentyle = anomalie)
    threshold_warning = np.percentile(scores, 100 - RCF_PERCENTILE_WARNING)  # P1
    threshold_critical = np.percentile(scores, 100 - RCF_PERCENTILE_CRITICAL)  # P0.1

    print(f"     â†’ PrÃ³g WARNING  (P{100-RCF_PERCENTILE_WARNING:.1f}): {threshold_warning:.3f}")
    print(f"     â†’ PrÃ³g CRITICAL (P{100-RCF_PERCENTILE_CRITICAL:.1f}): {threshold_critical:.3f}")
    print(f"     â†’ Min score: {scores.min():.3f} | Median: {np.median(scores):.3f}")

    # Wyniki do DF (tylko dla punktÃ³w produkcyjnych)
    prod_indices = prod_df.index
    df.loc[prod_indices, 'rcf_score'] = scores

    # --- NOWOÅšÄ†: JEDNOSTRONNY FILTR WIBRACYJNY (ANTY-FALSE-POSITIVE DLA POSTOJÃ“W) ---
    # RCF ma tendencjÄ™ do krzyczenia "ANOMALIA!" gdy maszyna naturalnie zwalnia na koniec zmiany (nagÅ‚y zanik wibracji).
    # Chcemy zgÅ‚aszaÄ‡ alarmy (Warning/Critical) TYLKO wtedy, gdy RCF znajdzie anomaliÄ™ ORAZ:
    # 1. Maszyna wibruje silniej niÅ¼ wynosi jej typowa "zdrowia" Å›rednia praca.
    # UÅ¼ywamy tolerancyjnego progu: wibracje muszÄ… byÄ‡ >= (0.8 * typowa Å›rednia produkcyjna).
    if 'vib_rms' in prod_df.columns:
        typical_vib = prod_df['vib_rms'].median()
        # MnoÅ¼ymy przez 0.8, aby pozwoliÄ‡ na alarmy "narastajÄ…ce", ale uciÄ…Ä‡ oczywiste puste zera z postoju
        is_vib_spike = df['vib_rms'] >= (typical_vib * 0.8)
    else:
        is_vib_spike = pd.Series(True, index=df.index)

    # Status tylko dla produkcji (poza produkcjÄ… bÄ™dzie IDLE lub nadpisane)
    rcf_status = pd.Series('IDLE', index=df.index)
    
    # Warunkowa klasyfikacja (niÅ¼szy score = anomalia PLUS rosnÄ…ce/zgodne wibracje)
    rcf_status[prod_mask] = np.where(
        (scores <= threshold_critical) & is_vib_spike[prod_mask],
        'ğŸ”´ KRITISK ALARM',
        np.where(
            (scores <= threshold_warning) & is_vib_spike[prod_mask],
            'ğŸŸ¡ PLANLEGG SERVICE',
            'ğŸŸ¢ MONITORING'
        )
    )
    df['rcf_status'] = rcf_status

    # Statystyki
    n_warning = (df['rcf_status'] == 'ğŸŸ¡ ANOMALIA RCF').sum()
    n_critical = (df['rcf_status'] == 'ğŸ”´ ANOMALIA KRYTYCZNA RCF').sum()
    print(f"     â†’ Wykryto: {n_warning} anomalii ğŸŸ¡ + {n_critical} anomalii ğŸ”´")

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 5: FUZJA ALARMÃ“W â€” WYNIK KOÅƒCOWY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fuse_alarms(df: pd.DataFrame) -> pd.DataFrame:
    """
    Fuzja alarmÃ³w z trzech silnikÃ³w diagnostycznych.

    Dwa etapy:
        1. Worst-case fusion (SIL-2, IEC 61508)
        2. Alarm Persistence / Debounce (SKF Enlight)

    Persistence (trwaÅ‚oÅ›Ä‡ alarmu):
        Alarm jest potwierdzony TYLKO gdy N kolejnych interwaÅ‚Ã³w przekracza prÃ³g.
        Ref: SKF IMx â€” "alarm debounce eliminates transient false alarms"

        Dlaczego? Prawdziwa degradacja Å‚oÅ¼yska to TREND, nie spike.
        Uderzenie kÅ‚ody o maszynÄ™ = 1 interwaÅ‚ z CF=4 â†’ ignoruj.
        PÄ™kniÄ™cie bieÅ¼ni = 20 interwaÅ‚Ã³w z CF=4 â†’ alarm.

        WyjÄ…tek: POÅ»AR/STOP nigdy nie jest debounce'owany â€” ryzyko zbyt duÅ¼e.
    """
    df = df.copy()

    # Zabezpieczenie przed brakujÄ…cymi kolumnami statusÃ³w
    for col in ['p_skf', 'p_siemens', 'p_aws', 'p_rcf']:
        if col not in df.columns: df[col] = 0
    for col in ['skf_status', 'siemens_status', 'aws_status', 'rcf_status']:
        if col not in df.columns: df[col] = 'IDLE'

    # Mapowanie priorytetÃ³w (wyÅ¼szy = gorszy)
    priority = {
        'IDLE': 0,
        'ğŸŸ¢ MONITORING': 1,
        'ğŸŸ¡ PLANLEGG SERVICE': 3,
        'ğŸ”´ KRITISK ALARM': 4,
        'ğŸ”´ğŸ”¥ BRANN/STOPP': 5,
        'UNKNOWN': 0
    }

    # Oblicz priorytety per silnik
    df['p_skf'] = df['skf_status'].map(priority).fillna(0)
    df['p_siemens'] = df['siemens_status'].map(priority).fillna(0)
    df['p_aws'] = df['aws_status'].map(priority).fillna(0)
    df['p_rcf'] = df['rcf_status'].map(priority).fillna(0)
    df['max_priority'] = df[['p_skf', 'p_siemens', 'p_aws', 'p_rcf']].max(axis=1)

    # â”€â”€ Alarm Persistence (Debounce) â”€â”€
    # Dla kaÅ¼dego silnika: ile kolejnych interwaÅ‚Ã³w alarm jest aktywny?
    # Alarm trwa = priorytet >= 3 (PLANLEGG SERVICE lub wyÅ¼ej)
    for col in ['p_skf', 'p_siemens', 'p_aws', 'p_rcf']:
        alarm_active = (df[col] >= 3).astype(int)
        # Oblicz ciÄ…g kolejnych jedynek (rolling count z resetem na 0)
        # UÅ¼yj cumsum trick: grupa = cumsum(~alarm) â†’ count w grupie
        groups = (~alarm_active.astype(bool)).cumsum()
        df[f'{col}_streak'] = alarm_active.groupby(groups).cumsum()

    # Persistence: alarm potwierdzony dopiero po N kolejnych interwaÅ‚ach
    for col, status_col in [('p_skf', 'skf_status'),
                            ('p_siemens', 'siemens_status'),
                            ('p_aws', 'aws_status'),
                            ('p_rcf', 'rcf_status')]:
        # Ekstremalny poÅ¼ar wymaga potÄ™Å¼nego gradientu I potwierdzenia, Å¼e to nie jest zimny start z mrozu.
        is_extreme_fire = False
        if 'temp_gradient_final' in df.columns and 'temp_mean' in df.columns:
            is_extreme_fire = (df['temp_gradient_final'] >= AWS_GRADIENT_FIRE_EXTREME) & (df['temp_mean'] >= AWS_MIN_FIRE_TEMP)
        
        # BRANN/STOPP (priorytet 5) â€” wymÃ³g potwierdzenia
        # CHYBA Å»E JEST TO EKSTREMALNY POÅ»AR (ktÃ³ry nie zmarzÅ‚) - wtedy bypass debouncingu (persistence = 0)
        is_fire_not_persistent = (
            (df[col] >= 5) &
            (df[f'{col}_streak'] < ALARM_PERSISTENCE_FIRE) &
            ~is_extreme_fire
        )
        # ZwykÅ‚e alarmy (priorytet 3-4) â€” peÅ‚na persistence 
        # Zmieniono: alarmy nie sÅ¡ juÅ¼ kasowane do statusu ZIELONEGO,
        # JeÅ¼eli alarm (np p=4) nie ma persistence, prÃ³bujemy zachowaÄ‡ chociaÅ¼ p=3 jeÅ›li pod spodem teÅ¼ krzyczy algorytm
        is_alarm_not_persistent = (
            (df[col] >= 3) &
            (df[col] < 5) &
            (df[f'{col}_streak'] < ALARM_PERSISTENCE_INTERVALS)
        )
        
        # Degradacja: zamiast na Å›lepo wrzucaÄ‡ ğŸŸ¢ MONITORING (p=1), 
        # zrzucamy nietrwaÅ‚e p>=4 do p=3 (SERVICE), a nietrwaÅ‚e p=3 do p=1
        df.loc[is_fire_not_persistent, col] = 4
        df.loc[is_fire_not_persistent, status_col] = 'ğŸ”´ KRITISK ALARM'
        
        unpersisted_crit = is_alarm_not_persistent & (df[col] == 4)
        df.loc[unpersisted_crit, col] = 3
        df.loc[unpersisted_crit, status_col] = 'ğŸŸ¡ PLANLEGG SERVICE'
        
        unpersisted_warn = is_alarm_not_persistent & (df[col] == 3)
        df.loc[unpersisted_warn, col] = 1
        df.loc[unpersisted_warn, status_col] = 'ğŸŸ¢ MONITORING'

    # Przelicz max_priority po debounce
    df['max_priority'] = df[['p_skf', 'p_siemens', 'p_aws', 'p_rcf']].max(axis=1)

    # Wynik koÅ„cowy
    conditions = [
        df['max_priority'] == 0,
        df['max_priority'] == 1,
        df['max_priority'].isin([2, 3]),
        df['max_priority'] == 4,
        df['max_priority'] >= 5
    ]
    choices = [
        'IDLE',
        'ğŸŸ¢ MONITORING',
        'ğŸŸ¡ PLANLEGG SERVICE',
        'ğŸ”´ KRITISK ALARM',
        'ğŸ”´ğŸ”¥ BRANN/STOPP'
    ]
    df['FINAL_VERDICT'] = np.select(conditions, choices, default='UNKNOWN')

    # Å¹rÃ³dÅ‚o alarmu
    def get_alarm_source(row):
        sources = []
        if row['p_skf'] >= 3:
            sources.append('SKF')
        if row['p_siemens'] >= 3:
            sources.append('Siemens')
        if row['p_aws'] >= 3:
            sources.append('AWS')
        if row['p_rcf'] >= 3:
            sources.append('RCF')
        return '+'.join(sources) if sources else '-'

    df['alarm_source'] = df.apply(get_alarm_source, axis=1)

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 6: HEALTH INDEX + PRAWDOPODOBIEÅƒSTWO AWARII
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_health_index(df: pd.DataFrame) -> pd.DataFrame:
    """
    Composite Health Index (0-100%) + P(awaria w ciÄ…gu 24h).

    Teoria (ISO 13381-1 / Augury / SparkCognition):
        Health Index Å‚Ä…czy wyniki 4 silnikÃ³w w jeden ciÄ…gÅ‚y wskaÅºnik.

        P(awaria) â€” sigmoidalna konwersja HI na prawdopodobieÅ„stwo.
        Kalibracja na prawdziwym poÅ¼arze 13.02.2026:
          - HI=100% â†’ Pâ‰ˆ1%   (Å‚oÅ¼ysko zdrowe)
          - HI=50%  â†’ Pâ‰ˆ15%  (wczesne zuÅ¼ycie)
          - HI=20%  â†’ Pâ‰ˆ75%  (zaawansowane uszkodzenie)
          - HI=0%   â†’ Pâ‰ˆ99%  (awaria nieunikniona)
    """
    df = df.copy()

    # â”€â”€ 1. Normalizacja komponentÃ³w do skali 0-100% â”€â”€

    # --- Komponent wibracyjny (Siemens baseline) ---
    # KLUCZOWA POPRAWKA: vib_rms â‰ˆ 0 przy wysokiej temp = Å‚oÅ¼ysko siÄ™ zaklinowaÅ‚o!
    dev_abs = df['baseline_deviation_pct'].abs().clip(0, 200)
    hi_vib = (1 - dev_abs / 200) * 100
    # Zakleszczenie = vib prawie zero, ALE temp roÅ›nie drastycznie szybciej niÅ¼ powinna!
    # UÅ¼ywamy wyliczonego gradientu temp - jeÅ¼eli waÅ‚ stoi (vib_rms < 0.01) ale grzeje siÄ™ tempem > 12C/h
    # Oznacza to potÄ™Å¼ne zaciÅ›niÄ™cie pasa / spalanie cewek silnika!
    seized_mask = (df['vib_rms'] < 0.01) & (df['temp_gradient_final'] > 12.0)
    hi_vib[seized_mask] = 0.0

    # --- Komponent gradientu temperatury (AWS) ---
    grad_pos = df['temp_gradient_final'].clip(lower=0)
    hi_grad = (1 - grad_pos / AWS_GRADIENT_CRITICAL).clip(0, 1) * 100
    # Desensytyzacja rozgrzewki: podczas warmup gradient jest naturalny
    if 'is_warmup' in df.columns:
        hi_grad[df['is_warmup']] = hi_grad[df['is_warmup']] * 0.5 + 50

    # --- Komponent absolutnej temperatury ---
    # > 55Â°C = zaczyna byÄ‡ niebezpieczne, > 90Â°C = krytyczne
    TEMP_SAFE = 55.0
    TEMP_CRITICAL = 90.0
    hi_abs_temp = ((TEMP_CRITICAL - df['temp_mean']) / (TEMP_CRITICAL - TEMP_SAFE)).clip(0, 1) * 100

    # --- NOWY: Komponent ISO 10816-1 (Absolutne normy wibracji) ---
    # Chroni przed "skaÅ¼onym baseline" â€” jeÅ›li maszyna wibruje Åºle od poczÄ…tku,
    # ISO to wychwyci, nawet jeÅ›li Siemens baseline mÃ³wi Å¼e jest "normalnie".
    # Klasa I: <0.71=100%, 1.8=50%, 4.5=0%
    if df['vib_rms'].max() > 0:
        hi_iso = np.interp(
            df['vib_rms'],
            [0, ISO_VIB_ZONE_A_B, ISO_VIB_ZONE_B_C, ISO_VIB_ZONE_C_D],
            [100, 100, 50, 0]
        )
    else:
        hi_iso = 100.0

    # --- Komponent CF (SKF) ---
    cf_norm = ((df['crest_factor'] - 1) / (SKF_CF_CRITICAL - 1)).clip(0, 1)
    hi_cf = (1 - cf_norm) * 100

    # --- Komponent RCF (Isolation Forest) ---
    rcf_norm = ((df['rcf_score'] + 0.2) / 0.3).clip(0, 1)
    hi_rcf = rcf_norm * 100

    # â”€â”€ 2. WaÅ¼ony Health Index â”€â”€
    # Wagi rebalansowane dla uwzglÄ™dnienia ISO (20%):
    W_VIB_REL = 0.20    # Siemens (relatywny do historii)
    W_VIB_ABS = 0.20    # ISO (absolutny do norm)
    W_GRAD = 0.20       # Gradient temperatury
    W_ABS_TEMP = 0.15   # Absolutna temperatura
    W_CF = 0.10         # Crest Factor
    W_RCF = 0.15        # Isolation Forest (wielowymiarowy)

    df['health_index'] = (
        W_VIB_REL * hi_vib +
        W_VIB_ABS * hi_iso +
        W_GRAD * hi_grad +
        W_ABS_TEMP * hi_abs_temp +
        W_CF * hi_cf +
        W_RCF * hi_rcf
    ).clip(0, 100)

    # Hard override: fizycznie niebezpieczne warunki
    # 1. Temperatura > 80Â°C = max HI = 30%
    df.loc[df['temp_mean'] > 80, 'health_index'] = df.loc[
        df['temp_mean'] > 80, 'health_index'].clip(upper=30)
    # 2. Gradient > 20Â°C/h = max HI = 25%
    df.loc[grad_pos > 20, 'health_index'] = df.loc[
        grad_pos > 20, 'health_index'].clip(upper=25)
    # 3. Zakleszczenie (vibâ‰ˆ0 + temp>40Â°C) = max HI = 15%
    df.loc[seized_mask, 'health_index'] = df.loc[
        seized_mask, 'health_index'].clip(upper=15)

    df.loc[~df['is_production'], 'health_index'] = np.nan

    # â”€â”€ 3. Trend HI (2h okno = 24 interwaÅ‚y) â”€â”€
    df['hi_trend'] = df['health_index'].diff(periods=24)

    # â”€â”€ 4. RUL (Remaining Useful Life) Prediction â”€â”€
    # Przewidujemy czas do osiÄ…gniÄ™cia HI = 15% (prÃ³g krytyczny)
    # RUL [h] = (Current_HI - Critical_HI) / (Degradation_Rate_per_hour)
    CRITICAL_HI = 15.0
    df['rul_hours'] = np.nan
    
    # Delta HI na godzinÄ™ (12 interwaÅ‚Ã³w po 5 min)
    hi_rate_per_hour = df['health_index'].diff(periods=12)
    
    # Oblicz RUL tylko gdy zdrowie SPADA (rate < 0)
    degrading = (hi_rate_per_hour < -0.1) & (df['health_index'] > CRITICAL_HI)
    df.loc[degrading, 'rul_hours'] = (
        (df.loc[degrading, 'health_index'] - CRITICAL_HI) / 
        (-hi_rate_per_hour.loc[degrading])
    ).clip(0, 168) # Max 1 tydzieÅ„ prognozy

    # â”€â”€ 5. P(awaria) â€” sigmoid z recalibrowanymi parametrami â”€â”€
    # Steilsza krzywa: k=10 (byÅ‚o 8), midpoint x0=0.45 (byÅ‚o 0.35)
    # Efekt: P roÅ›nie szybciej gdy HI spada poniÅ¼ej 45%
    SIGMOID_K = 10
    SIGMOID_X0 = 0.45
    hi_norm = df['health_index'].fillna(100) / 100
    base_p = 1 / (1 + np.exp(-SIGMOID_K * (SIGMOID_X0 - hi_norm)))

    # Silniejszy modyfikator trendu: spadajÄ…cy HI â†’ +30% P (byÅ‚o +20%)
    trend_mod = (-df['hi_trend'].fillna(0) / 100).clip(0, 0.30)
    df['failure_probability'] = (base_p + trend_mod).clip(0, 0.99) * 100
    df.loc[~df['is_production'], 'failure_probability'] = np.nan

    # â”€â”€ 5. Klasyfikacja ryzyka â”€â”€
    conditions = [
        ~df['is_production'],
        df['failure_probability'] <= 5,
        (df['failure_probability'] > 5) & (df['failure_probability'] <= 25),
        (df['failure_probability'] > 25) & (df['failure_probability'] <= 60),
        df['failure_probability'] > 60
    ]
    choices = [
        'IDLE',
        'ğŸŸ¢ NISKIE (0-5%)',
        'ğŸŸ¡ UMIARKOWANE (5-25%)',
        'ğŸŸ  WYSOKIE (25-60%)',
        'ğŸ”´ KRYTYCZNE (>60%)'
    ]
    df['risk_level'] = np.select(conditions, choices, default='UNKNOWN')

    return df


def print_health_report(df: pd.DataFrame):
    """Drukuj raport Health Index z prawdopodobieÅ„stwem awarii."""
    prod = df[df['is_production'] == True].copy()
    if len(prod) == 0:
        return

    print(f"\n{'â•' * 80}")
    print(f"  ğŸ¥ HEALTH INDEX â€” PRAWDOPODOBIEÅƒSTWO AWARII")
    print(f"{'â•' * 80}")

    # Ostatni znany stan
    last = prod.iloc[-1]
    
    # Formatowanie RUL
    rul_text = "STABILNY"
    if not np.isnan(last['rul_hours']):
        if last['rul_hours'] < 1:
            rul_text = f"ğŸ”´ KATASTROFA (< 1h!)"
        elif last['rul_hours'] < 24:
            rul_text = f"ğŸŸ  {last['rul_hours']:.1f} h (DziÅ›!)"
        else:
            rul_text = f"ğŸŸ¡ {last['rul_hours']/24:.1f} dni"

    print(f"\n  ğŸ“ Ostatni pomiar: {prod.index[-1]}")
    print(f"     Health Index:                  {last['health_index']:.0f}%")
    print(f"     P(awaria w ciÄ…gu 24h):         {last['failure_probability']:.1f}%")
    print(f"     Trend (ostatnie 2h):           {last['hi_trend']:+.1f}%" if not np.isnan(last['hi_trend']) else f"     Trend:                         brak danych")
    print(f"     RUL (Prognoza czasu pracy):    {rul_text}")
    print(f"     Poziom ryzyka:                 {last['risk_level']}")

    # RozkÅ‚ad ryzyka
    print(f"\n  ğŸ“Š RozkÅ‚ad ryzyka (caÅ‚y okres):")
    for level in ['ğŸŸ¢ NISKIE (0-5%)', 'ğŸŸ¡ UMIARKOWANE (5-25%)',
                  'ğŸŸ  WYSOKIE (25-60%)', 'ğŸ”´ KRYTYCZNE (>60%)']:
        count = (df['risk_level'] == level).sum()
        pct = count / len(prod) * 100
        print(f"     {level}: {count:,} ({pct:.1f}%)")

    # Top 10
    print(f"\n  ğŸ” TOP 10 â€” NajwyÅ¼sze P(awaria) / NajniÅ¼szy RUL:")
    top = prod.nlargest(10, 'failure_probability')
    for idx, row in top.iterrows():
        rt = f"{row['rul_hours']:.1f}h" if not np.isnan(row['rul_hours']) else "---"
        print(f"     {idx}  HI={row['health_index']:4.0f}%  "
              f"P={row['failure_probability']:5.1f}%  "
              f"RUL={rt:>6}  "
              f"T={row['temp_mean']:5.1f}Â°")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODUÅ 7: RAPORT BIZNESOWY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_header():
    """Wydrukuj nagÅ‚Ã³wek raportu."""
    print("\n")
    print("â•”" + "â•" * 96 + "â•—")
    print("â•‘  DIAGNOSTIKKRAPPORT â€” LAGERMONITORINGSSYSTEM" + " " * 50 + "â•‘")
    print("â•‘  Metode: SKF Crest Factor + Siemens Baseline + AWS Monitron Gradient" + " " * 24 + "â•‘")
    print("â•‘  Standard: ISO 13373-1 / IEC 61508 (SIL-2 alarm fusion)" + " " * 39 + "â•‘")
    print("â• " + "â•" * 96 + "â•£")
    print("â•‘  ALARMFORKLARING:" + " " * 78 + "â•‘")
    print("â•‘    ğŸŸ¢ MONITORING      â€” Stabil drift, ingen handling nÃ¸dvendig" + " " * 29 + "â•‘")
    print("â•‘    ğŸŸ¡ PLANLEGG SERVICE â€” Planlegg lagerskifte innen 2-4 uker" + " " * 30 + "â•‘")
    print("â•‘    ğŸ”´ BRANN/STOPP      â€” STOPP LINJEN! Risiko for brann/havari" + " " * 25 + "â•‘")
    print("â•š" + "â•" * 96 + "â•")


def print_summary_stats(df: pd.DataFrame):
    """Wydrukuj podsumowanie statystyczne."""
    total = len(df)
    idle = len(df[df['FINAL_VERDICT'] == 'IDLE'])
    ok = len(df[df['FINAL_VERDICT'] == 'ğŸŸ¢ MONITORING'])
    warn = len(df[df['FINAL_VERDICT'] == 'ğŸŸ¡ PLANLEGG SERVICE'])
    crit = len(df[df['FINAL_VERDICT'].str.contains('ğŸ”´', na=False)])

    print(f"\n{'â”€' * 80}")
    print(f"  ğŸ“Š STATISTISK OPPSUMMERING ({total} 5-minutters intervaller)")
    print(f"{'â”€' * 80}")
    print(f"  âš™ï¸  IDLE (maskin av): {idle:>6}  ({idle/total*100:5.1f}%)")
    print(f"  ğŸŸ¢ MONITORING (stabil):       {ok:>6}  ({ok/total*100:5.1f}%)")
    print(f"  ğŸŸ¡ PLANLEGG SERVICE (trend):   {warn:>6}  ({warn/total*100:5.1f}%)")
    print(f"  ğŸ”´ KRITISK ALARM / BRANN:      {crit:>6}  ({crit/total*100:5.1f}%)")
    print(f"{'â”€' * 80}")

    # Temperatura
    print(f"\n  ğŸŒ¡ï¸  TEMPERATURA ÅOÅ»YSKA:")
    print(f"      Min: {df['temp_mean'].min():6.1f}Â°C | "
          f"Åšrednia: {df['temp_mean'].mean():6.1f}Â°C | "
          f"Max: {df['temp_mean'].max():6.1f}Â°C")

    # Wibracje
    running = df[df['vib_rms'] > SKF_VIBRATION_IDLE]
    if len(running) > 0:
        print(f"\n  ğŸ“³ WIBRACJE (gdy maszyna pracuje):")
        print(f"      RMS Min: {running['vib_rms'].min():.3f}g | "
              f"Åšrednia: {running['vib_rms'].mean():.3f}g | "
              f"Max: {running['vib_rms'].max():.3f}g")
        print(f"      Crest Factor Min: {running['crest_factor'].min():.2f} | "
              f"Åšredni: {running['crest_factor'].mean():.2f} | "
              f"Max: {running['crest_factor'].max():.2f}")

    # Gradient
    print(f"\n  ğŸ“ˆ GRADIENT TEMPERATURY:")
    print(f"      Max wzrost: {df['temp_gradient_final'].max():+.1f}Â°C/h | "
          f"Max spadek: {df['temp_gradient_final'].min():+.1f}Â°C/h")


def print_alarm_events(df: pd.DataFrame):
    """Wydrukuj szczegÃ³Å‚owÄ… listÄ™ zdarzeÅ„ alarmowych."""
    alarms = df[df['FINAL_VERDICT'].str.contains('SERVICE|ALARM|BRANN', na=False)].copy()

    if len(alarms) == 0:
        print("\n  âœ… BRAK ALARMÃ“W â€” Maszyna pracuje w normie przez caÅ‚y analizowany okres.")
        return

    print(f"\n{'â•' * 100}")
    print(f"  âš ï¸  ZDARZENIA ALARMOWE ({len(alarms)} interwaÅ‚Ã³w)")
    print(f"{'â•' * 100}")
    print(f"  {'Czas':<22} â”‚ {'Temp':>6} â”‚ {'Vib_RMS':>7} â”‚ {'CF':>5} â”‚ "
          f"{'Î”%Baza':>7} â”‚ {'Î”T/h':>6} â”‚ {'Å¹rÃ³dÅ‚o':>8} â”‚ Status")
    print(f"  {'â”€' * 22}â”€â”¼â”€{'â”€' * 6}â”€â”¼â”€{'â”€' * 7}â”€â”¼â”€{'â”€' * 5}â”€â”¼â”€"
          f"{'â”€' * 7}â”€â”¼â”€{'â”€' * 6}â”€â”¼â”€{'â”€' * 8}â”€â”¼â”€{'â”€' * 30}")

    # Grupuj ciÄ…gÅ‚e zdarzenia alarmowe aby nie zalewaÄ‡ konsoli
    # PokaÅ¼ pierwsze i ostatnie zdarzenie z kaÅ¼dej grupy
    prev_verdict = None
    group_start = None
    group_count = 0

    for idx, row in alarms.iterrows():
        current_verdict = row['FINAL_VERDICT']

        if current_verdict != prev_verdict:
            # Nowa grupa alarmowa
            if group_count > 2 and prev_verdict is not None:
                print(f"  {'... (' + str(group_count - 2) + ' wiÄ™cej)':<22} â”‚ {'':>6} â”‚ "
                      f"{'':>7} â”‚ {'':>5} â”‚ {'':>7} â”‚ {'':>6} â”‚ {'':>8} â”‚")

            timestamp_str = idx.strftime('%Y-%m-%d %H:%M')
            print(f"  {timestamp_str:<22} â”‚ {row['temp_mean']:>5.1f}Â° â”‚ "
                  f"{row['vib_rms']:>7.3f} â”‚ {row['crest_factor']:>5.2f} â”‚ "
                  f"{row['baseline_deviation_pct']:>+6.0f}% â”‚ "
                  f"{row['temp_gradient_final']:>+5.1f}Â° â”‚ "
                  f"{row['alarm_source']:>8} â”‚ {current_verdict}")
            group_start = idx
            group_count = 1
            prev_verdict = current_verdict
        else:
            group_count += 1
            if group_count <= 2:
                timestamp_str = idx.strftime('%Y-%m-%d %H:%M')
                print(f"  {timestamp_str:<22} â”‚ {row['temp_mean']:>5.1f}Â° â”‚ "
                      f"{row['vib_rms']:>7.3f} â”‚ {row['crest_factor']:>5.2f} â”‚ "
                      f"{row['baseline_deviation_pct']:>+6.0f}% â”‚ "
                      f"{row['temp_gradient_final']:>+5.1f}Â° â”‚ "
                      f"{row['alarm_source']:>8} â”‚ {current_verdict}")

    # Ostatnia grupa
    if group_count > 2:
        print(f"  {'... (' + str(group_count - 2) + ' wiÄ™cej)':<22} â”‚ {'':>6} â”‚ "
              f"{'':>7} â”‚ {'':>5} â”‚ {'':>7} â”‚ {'':>6} â”‚ {'':>8} â”‚")


def print_recommendations(df: pd.DataFrame):
    """Wydrukuj rekomendacje dziaÅ‚aÅ„ na podstawie wynikÃ³w analizy."""
    alarms = df[df['FINAL_VERDICT'].str.contains('SERVICE|ALARM|BRANN', na=False)]

    print(f"\n{'â•' * 80}")
    print("  ğŸ“‹ REKOMENDACJE DLA ZARZÄ„DU / KIEROWNIKA UR")
    print(f"{'â•' * 80}")

    if len(alarms) == 0:
        print("  âœ… Brak wymaganych dziaÅ‚aÅ„. KontynuowaÄ‡ monitoring.")
        return

    has_fire = df['FINAL_VERDICT'].str.contains('BRANN', na=False).any()
    has_critical = df['FINAL_VERDICT'].str.contains('KRITISK', na=False).any()
    has_service = df['FINAL_VERDICT'].str.contains('SERVICE', na=False).any()

    rec_num = 1
    if has_fire:
        print(f"\n  ğŸ”´ REKOMENDACJA {rec_num}: NATYCHMIASTOWE ZATRZYMANIE")
        print(f"     Wykryto krytyczny gradient temperatury (>{AWS_GRADIENT_CRITICAL}Â°C/h).")
        print(f"     Uzasadnienie: Zgodnie z AWS Monitron methodology, szybki wzrost")
        print(f"     temperatury wskazuje na utratÄ™ smarowania lub zacieranie (ğŸ”´ğŸ”¥ BRANN/STOPP).")
        print(f"     RYZYKO: PoÅ¼ar Å‚oÅ¼yska w ciÄ…gu 1-3 godzin bez interwencji.")
        print(f"     AKCJA: Zatrzymaj liniÄ™. SprawdÅº smarowanie i stan bieÅ¼ni.")
        rec_num += 1

    if has_critical:
        print(f"\n  ğŸ”´ REKOMENDACJA {rec_num}: WYMIANA ÅOÅ»YSKA W CIÄ„GU 48H")
        print(f"     Wykryto krytyczne odchylenie od normy pracy lub wysoki Crest Factor.")
        print(f"     Uzasadnienie: Analiza SKF/Siemens wskazuje na zaawansowane")
        print(f"     uszkodzenie mechaniczne bieÅ¼ni lub kulek Å‚oÅ¼yska.")
        print(f"     AKCJA: ZamÃ³w Å‚oÅ¼ysko. Zaplanuj wymianÄ™ na najbliÅ¼szy przestÃ³j.")
        rec_num += 1

    if has_service:
        print(f"\n  ğŸŸ¡ REKOMENDACJA {rec_num}: PLANOWANY SERWIS (2-4 TYGODNIE)")
        print(f"     Wykryto trend wzrostowy wibracji lub temperatury.")
        print(f"     Uzasadnienie: Siemens Baseline Deviation wskazuje na")
        print(f"     postÄ™pujÄ…ce zuÅ¼ycie (ğŸŸ¡ PLANLEGG SERVICE).")
        print(f"     AKCJA: ZamÃ³w czÄ™Å›ci. Zaplanuj wymianÄ™ w ramach planowego przestoju.")
        rec_num += 1

    # Podsumowanie kosztÃ³w
    print(f"\n  ğŸ’° UZASADNIENIE EKONOMICZNE:")
    print(f"     Koszt planowanej wymiany Å‚oÅ¼yska:     ~2,000-5,000 PLN")
    print(f"     Koszt nieplanowanego przestoju (1h):   ~10,000-30,000 PLN")
    print(f"     Koszt poÅ¼aru i odbudowy linii:         ~500,000-2,000,000 PLN")
    print(f"     â†’ Prewencja jest 100-400Ã— taÅ„sza niÅ¼ awaria.")


def export_results(df: pd.DataFrame, output_path: str):
    """Eksportuj wyniki analizy do CSV."""
    export_cols = [
        'sn',
        'is_production', 'is_break', 'is_warmup',
        'temp_mean', 'vib_rms', 'vib_max', 'crest_factor', 'avg_line_vibration',
        'baseline_7d', 'baseline_deviation_pct',
        'temp_gradient_final',
        'rcf_score',
        'health_index', 'failure_probability', 'rul_hours', 'risk_level',
        'skf_status', 'siemens_status', 'aws_status', 'rcf_status',
        'FINAL_VERDICT', 'alarm_source'
    ]
    existing_cols = [c for c in export_cols if c in df.columns]
    df[existing_cols].to_csv(output_path, sep=';', encoding='utf-8-sig')
    print(f"\n  ğŸ’¾ Wyniki zapisane do: {output_path}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN â€” URUCHOMIENIE ANALIZY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    GÅ‚Ã³wna funkcja analizy. Uruchamia kolejno:
    1. Åadowanie danych
    2. Agregacja 5-minutowa
    3. Analiza SKF (Crest Factor)
    4. Analiza Siemens (Baseline Deviation)
    5. Analiza AWS Monitron (Temperature Gradient)
    6. Analiza RCF (Random Cut Forest â€” ML)
    7. Fuzja alarmÃ³w
    8. Raport biznesowy
    """
    print("â•”" + "â•" * 70 + "â•—")
    print("â•‘  URUCHAMIANIE SYSTEMU DIAGNOSTYCZNEGO" + " " * 32 + "â•‘")
    print("â•‘  Bearing Condition Monitor v2.0 (z Random Cut Forest)" + " " * 16 + "â•‘")
    print("â•š" + "â•" * 70 + "â•")

    # ÅšcieÅ¼ki do plikÃ³w
    script_dir = os.path.dirname(os.path.abspath(__file__))
    file_paths = {
        "OV": "dane_lozysko_projektOV.csv",
        "OH": "dane_lozysko_projektOH.csv",
        "NH": "dane_lozysko_projektNH.csv",
        "NV": "dane_lozysko_projektNV.csv"
    }
    hall_file = os.path.join(script_dir, 'dane_hala_projekt.csv')

    # â”€â”€ Krok 1: Åadowanie danych â”€â”€
    print("\nğŸ“¥ KROK 1/9: Åadowanie danych z czujnikÃ³w IoT (Sklejenie z 4 wrzecion)...")
    
    dfs = []
    for label, filename in file_paths.items():
        filepath = os.path.join(script_dir, filename)
        if os.path.exists(filepath):
            df_part = load_sensor_data(filepath)
            
            # Wzbogacenie identyfikatora czujnika o pozycjÄ™ na maszynie dla czytelnych raportÃ³w
            df_part['sn'] = df_part['sn'].astype(str) + f" ({label})"
            dfs.append(df_part)
        else:
            print(f"  âš ï¸  Brak pliku: {filename}")
            
    if not dfs:
        print("âŒ Brak jakichkolwiek plikÃ³w z danymi Å‚oÅ¼ysk! Zatrzymanie analizy.")
        return
        
    bearing_raw = pd.concat(dfs, ignore_index=True)

    hall_temp = None
    if os.path.exists(hall_file):
        hall_raw = load_sensor_data(hall_file)
        hall_temp_df = prepare_hall_data(hall_raw)
        hall_temp = hall_temp_df['hall_temp'] if isinstance(hall_temp_df, pd.DataFrame) else hall_temp_df
    else:
        print("  âš ï¸  Brak danych halowych â€” gradient bez kompensacji otoczenia")

    # â”€â”€ Krok 2: Przygotowanie danych per silnik i korelacja (Saga) â”€â”€
    print(f"\nğŸ“Š KROK 2/9: Agregacja do interwaÅ‚Ã³w {AGGREGATION_INTERVAL} i grupowanie po czujnikach...")
    aggregated_sensors = {}
    for sn, sensor_data in bearing_raw.groupby('sn'):
        print(f"     â†’ Przetwarzanie napÄ™du SN: {sn}...")
        df_sensor = prepare_bearing_data(sensor_data)
        df_sensor['sn'] = sn
        aggregated_sensors[sn] = df_sensor

    if not aggregated_sensors:
        print("Brak poprawnych danych do analizy.")
        return

    # Oblicz wspÃ³lnÄ… wibracjÄ™ (Avg Line Vibration)
    all_vib = pd.DataFrame({sn: df['vib_rms'] for sn, df in aggregated_sensors.items()})
    avg_line_vib = all_vib.mean(axis=1)

    # â”€â”€ Analiza dla kaÅ¼dego silnika niezaleÅ¼nie â”€â”€
    final_dfs = []
    
    for sn, df_sensor in aggregated_sensors.items():
        print(f"\n{'â•' * 80}")
        print(f"  ğŸ”„ ROZPOCZÄ˜CIE ANALIZY DLA SILNIKA / CZUJNIKA SN: {sn}")
        print(f"{'â•' * 80}")
        df = df_sensor.copy()
        
        # Wstrzyknij 'avg_line_vibration' dla tego silnika
        df['avg_line_vibration'] = avg_line_vib
        
        # â”€â”€ Krok 3: SKF Crest Factor â”€â”€
        print("ğŸ”§ KROK 3/9: Analiza SKF â€” Crest Factor (uszkodzenia mechaniczne)...")
        df = analyze_skf_crest_factor(df)

        # â”€â”€ Krok 4: Siemens Baseline â”€â”€
        print("ğŸ“ KROK 4/9: Analiza Siemens â€” Adaptive Baseline (banda Î¼Â±2Ïƒ)...")
        df = analyze_siemens_baseline(df)

        # â”€â”€ Krok 5: AWS Gradient â”€â”€
        print("ğŸŒ¡ï¸  KROK 5/9: Analiza AWS Monitron â€” Gradient temperatury...")
        df = analyze_aws_gradient(df, hall_temp)

        # â”€â”€ Krok 6: Random Cut Forest â”€â”€
        print("ğŸŒ² KROK 6/9: Analiza RCF â€” Random Cut Forest (wielowymiarowy ML)...")
        df = analyze_rcf_anomaly(df)

        # â”€â”€ Krok 7: Fuzja alarmÃ³w â”€â”€
        print("âš¡ KROK 7/9: Fuzja alarmÃ³w (worst-case, SIL-2 + persistence)...")
        df = fuse_alarms(df)

        # â”€â”€ Krok 8: Health Index + P(awaria) â”€â”€
        print("ğŸ¥ KROK 8/9: Health Index + P(awaria w ciÄ…gu 24h)...")
        df = calculate_health_index(df)
        
        final_dfs.append(df)
    
    # ZÅ‚Ä…czenie wynikÃ³w do raportu
    all_results_df = pd.concat(final_dfs).sort_index()

    # â”€â”€ Krok 9: Raport (Wersja Zbiorcza i Osobna) â”€â”€
    print("\nğŸ“‹ KROK 9/9: Generowanie raportu...")
    print_header()
    
    for sn, df_sensor_final in zip(aggregated_sensors.keys(), final_dfs):
        print(f"\n{'=' * 80}")
        print(f"  RAPORT WYNIKOWY DLA SN: {sn}")
        print(f"{'=' * 80}")
        print_summary_stats(df_sensor_final)
        print_alarm_events(df_sensor_final)
        print_health_report(df_sensor_final)
        print_recommendations(df_sensor_final)

    # â”€â”€ Eksport wynikÃ³w â”€â”€
    output_path = os.path.join(script_dir, 'raport_diagnostyczny.csv')
    export_results(all_results_df, output_path)

    print(f"\n{'â•' * 80}")
    print(f"  âœ… ANALIZA KASKADOWA ZAKOÅƒCZONA")
    print(f"     Przeanalizowano silniki: {list(aggregated_sensors.keys())}")
    print(f"     ÅÄ…cznie interwaÅ‚Ã³w: {len(all_results_df)}")
    print(f"     Zakres dat: {all_results_df.index.min()} â€” {all_results_df.index.max()}")
    print(f"{'â•' * 80}\n")

    return all_results_df


if __name__ == '__main__':
    result = main()
